{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Reshape\n",
    "from keras.layers.core import Activation\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.convolutional import UpSampling2D\n",
    "from keras.layers.convolutional import Conv2D, MaxPooling2D\n",
    "from keras.layers.core import Flatten\n",
    "from keras.optimizers import SGD\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import math\n",
    "\n",
    "from keras.datasets import mnist\n",
    "\n",
    "class GAN(object):\n",
    "    def __init__(self, input_shape=(28,28,1)):\n",
    "        self.input_shape = input_shape\n",
    "        self.generator = self.generator_model()\n",
    "        self.discriminator = self.discriminator_model()\n",
    "        self.gan = self.build_model(self.generator, self.discriminator)\n",
    "    \n",
    "    def generator_model(self):\n",
    "        model = Sequential()\n",
    "        model.add(Dense(input_dim=100, units=1024))\n",
    "        model.add(Activation('tanh'))\n",
    "        model.add(Dense(128*7*7))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Activation('tanh'))\n",
    "        model.add(Reshape((7, 7, 128), input_shape=(128*7*7,)))\n",
    "        model.add(UpSampling2D(size=(2, 2)))\n",
    "        model.add(Conv2D(64, (5, 5), padding='same'))\n",
    "        model.add(Activation('tanh'))\n",
    "        model.add(UpSampling2D(size=(2, 2)))\n",
    "        model.add(Conv2D(1, (5, 5), padding='same'))\n",
    "        model.add(Activation('tanh'))\n",
    "        return model\n",
    "\n",
    "    def discriminator_model(self):\n",
    "        model = Sequential()\n",
    "        model.add(Conv2D(64, (5, 5), padding='same', input_shape=self.input_shape))\n",
    "        model.add(Activation('tanh'))\n",
    "        model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "        model.add(Conv2D(128, (5, 5)))\n",
    "        model.add(Activation('tanh'))\n",
    "        model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "        model.add(Flatten())\n",
    "        model.add(Dense(1024))\n",
    "        model.add(Activation('tanh'))\n",
    "        model.add(Dense(1))\n",
    "        model.add(Activation('sigmoid'))\n",
    "        return model\n",
    "\n",
    "    def build_model(self, g, d):\n",
    "        model = Sequential()\n",
    "        model.add(g)\n",
    "        d.trainable = False\n",
    "        model.add(d)\n",
    "        return model\n",
    "\n",
    "    def train(self, X_train, Y_train, X_test, Y_test, epochs=100, batch_size=32):\n",
    "        d_optimizer = SGD(lr=0.0005, momentum=0.9, nesterov=True)\n",
    "        g_optimizer = SGD(lr=0.0005, momentum=0.9, nesterov=True)\n",
    "        self.generator.compile(loss='binary_crossentropy', optimizer=\"SGD\")\n",
    "        self.gan.compile(loss='binary_crossentropy', optimizer=g_optimizer)\n",
    "        self.discriminator.trainable = True\n",
    "        self.discriminator.compile(loss='binary_crossentropy', optimizer=d_optimizer)\n",
    "        for epoch in range(1,epochs):\n",
    "            print(\"Epoch {}\".format(epoch))\n",
    "            for index in range(int(X_train.shape[0]/batch_size)):\n",
    "                rand_vector = np.random.uniform(-1, 1, size=(batch_size, 100))\n",
    "                image_batch = X_train[index*batch_size:(index+1) * batch_size]\n",
    "                generated_images = self.generator.predict(rand_vector, verbose=0)\n",
    "                X = np.concatenate((image_batch, generated_images))\n",
    "                y = [1] * batch_size + [0] * batch_size\n",
    "                d_loss = self.discriminator.train_on_batch(X, y)\n",
    "                rand_vector = np.random.uniform(-1, 1, (batch_size,  100))\n",
    "                self.discriminator.trainable = False\n",
    "                g_loss = self.gan.train_on_batch(rand_vector, [1] * batch_size)\n",
    "                self.discriminator.trainable = True\n",
    "                print(\"\\rbatch {} d loss: {} g loss: {}\".format(index, d_loss, g_loss), end=\"\")\n",
    "            print()\n",
    "                \n",
    "\n",
    "if __name__ == '__main__':\n",
    "    (X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "    X_train = (X_train.astype(np.float32) - 127.5)/127.5\n",
    "    X_train = X_train[:, :, :, None]\n",
    "    X_test = X_test[:, :, :, None]\n",
    "    dcgan = GAN()\n",
    "    dcgan.train(X_train, y_train, X_test, y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
