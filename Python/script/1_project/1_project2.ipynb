{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold, cross_val_score, cross_val_predict\n",
    "from sklearn import metrics\n",
    "\n",
    "from sklearn import svm\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "# from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import RandomForestRegressor,RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>년도</th>\n",
       "      <th>귤도매가격</th>\n",
       "      <th>귤소매가격</th>\n",
       "      <th>오렌지도매가격</th>\n",
       "      <th>오렌지소매가격</th>\n",
       "      <th>생산자물가지수(감귤)</th>\n",
       "      <th>소비자물가지수(감귤)</th>\n",
       "      <th>1인당 가처분소득</th>\n",
       "      <th>1인당 연간소비량(kg)</th>\n",
       "      <th>오렌지가격_1kg</th>\n",
       "      <th>오렌지가공매출_백만원</th>\n",
       "      <th>오렌지가공량_ton</th>\n",
       "      <th>감귤가격_1kg</th>\n",
       "      <th>감귤가공매출_백만원</th>\n",
       "      <th>감귤가공량_ton</th>\n",
       "      <th>감귤처리량</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1998</td>\n",
       "      <td>10884.666670</td>\n",
       "      <td>11929.333330</td>\n",
       "      <td>21830.00000</td>\n",
       "      <td>45000.0</td>\n",
       "      <td>95.98</td>\n",
       "      <td>80.644</td>\n",
       "      <td>57194.3727</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2310</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13836.0</td>\n",
       "      <td>1326</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5012</td>\n",
       "      <td>500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1999</td>\n",
       "      <td>6206.000000</td>\n",
       "      <td>11933.333330</td>\n",
       "      <td>30530.00000</td>\n",
       "      <td>93240.0</td>\n",
       "      <td>113.29</td>\n",
       "      <td>102.156</td>\n",
       "      <td>58382.7420</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3202</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15070.0</td>\n",
       "      <td>1512</td>\n",
       "      <td>NaN</td>\n",
       "      <td>33142</td>\n",
       "      <td>567041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2000</td>\n",
       "      <td>7417.333333</td>\n",
       "      <td>11800.000000</td>\n",
       "      <td>14240.00000</td>\n",
       "      <td>52580.0</td>\n",
       "      <td>58.74</td>\n",
       "      <td>55.410</td>\n",
       "      <td>61964.6448</td>\n",
       "      <td>11.9</td>\n",
       "      <td>1538</td>\n",
       "      <td>188000.0</td>\n",
       "      <td>11375.0</td>\n",
       "      <td>936</td>\n",
       "      <td>NaN</td>\n",
       "      <td>27468</td>\n",
       "      <td>430617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2001</td>\n",
       "      <td>6356.000000</td>\n",
       "      <td>11066.666670</td>\n",
       "      <td>17780.00000</td>\n",
       "      <td>51290.0</td>\n",
       "      <td>90.97</td>\n",
       "      <td>79.033</td>\n",
       "      <td>68150.2896</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1898</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10869.0</td>\n",
       "      <td>1194</td>\n",
       "      <td>NaN</td>\n",
       "      <td>47445</td>\n",
       "      <td>527326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2002</td>\n",
       "      <td>5312.000000</td>\n",
       "      <td>8866.666667</td>\n",
       "      <td>22410.00000</td>\n",
       "      <td>63440.0</td>\n",
       "      <td>84.83</td>\n",
       "      <td>84.325</td>\n",
       "      <td>75338.7816</td>\n",
       "      <td>13.3</td>\n",
       "      <td>2390</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8229.0</td>\n",
       "      <td>1099</td>\n",
       "      <td>NaN</td>\n",
       "      <td>112359</td>\n",
       "      <td>531081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>2003</td>\n",
       "      <td>9075.000000</td>\n",
       "      <td>26300.000000</td>\n",
       "      <td>17700.00000</td>\n",
       "      <td>56280.0</td>\n",
       "      <td>57.45</td>\n",
       "      <td>63.620</td>\n",
       "      <td>82105.3168</td>\n",
       "      <td>13.0</td>\n",
       "      <td>1904</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19712.0</td>\n",
       "      <td>900</td>\n",
       "      <td>NaN</td>\n",
       "      <td>120333</td>\n",
       "      <td>477523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>2004</td>\n",
       "      <td>12609.000000</td>\n",
       "      <td>27000.000000</td>\n",
       "      <td>18720.00000</td>\n",
       "      <td>58280.0</td>\n",
       "      <td>96.77</td>\n",
       "      <td>85.198</td>\n",
       "      <td>90825.8304</td>\n",
       "      <td>12.0</td>\n",
       "      <td>2006</td>\n",
       "      <td>NaN</td>\n",
       "      <td>24065.0</td>\n",
       "      <td>1337</td>\n",
       "      <td>NaN</td>\n",
       "      <td>100517</td>\n",
       "      <td>415338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>2005</td>\n",
       "      <td>12133.000000</td>\n",
       "      <td>16500.000000</td>\n",
       "      <td>16700.00000</td>\n",
       "      <td>63520.0</td>\n",
       "      <td>143.35</td>\n",
       "      <td>106.735</td>\n",
       "      <td>95684.7528</td>\n",
       "      <td>13.1</td>\n",
       "      <td>1814</td>\n",
       "      <td>NaN</td>\n",
       "      <td>25366.0</td>\n",
       "      <td>1795</td>\n",
       "      <td>NaN</td>\n",
       "      <td>125343</td>\n",
       "      <td>491260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>2006</td>\n",
       "      <td>13026.000000</td>\n",
       "      <td>31800.000000</td>\n",
       "      <td>18650.00000</td>\n",
       "      <td>63380.0</td>\n",
       "      <td>100.05</td>\n",
       "      <td>84.334</td>\n",
       "      <td>99341.6424</td>\n",
       "      <td>12.7</td>\n",
       "      <td>1998</td>\n",
       "      <td>NaN</td>\n",
       "      <td>26547.0</td>\n",
       "      <td>1426</td>\n",
       "      <td>NaN</td>\n",
       "      <td>109496</td>\n",
       "      <td>450087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>2007</td>\n",
       "      <td>7101.000000</td>\n",
       "      <td>13100.000000</td>\n",
       "      <td>23090.00000</td>\n",
       "      <td>70610.0</td>\n",
       "      <td>157.50</td>\n",
       "      <td>109.137</td>\n",
       "      <td>107368.2552</td>\n",
       "      <td>16.0</td>\n",
       "      <td>2445</td>\n",
       "      <td>NaN</td>\n",
       "      <td>24101.0</td>\n",
       "      <td>1582</td>\n",
       "      <td>NaN</td>\n",
       "      <td>138782</td>\n",
       "      <td>513746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>2008</td>\n",
       "      <td>12719.000000</td>\n",
       "      <td>22100.000000</td>\n",
       "      <td>19320.00000</td>\n",
       "      <td>60350.0</td>\n",
       "      <td>59.02</td>\n",
       "      <td>67.663</td>\n",
       "      <td>116943.7992</td>\n",
       "      <td>13.0</td>\n",
       "      <td>2066</td>\n",
       "      <td>NaN</td>\n",
       "      <td>25655.0</td>\n",
       "      <td>1240</td>\n",
       "      <td>NaN</td>\n",
       "      <td>88664</td>\n",
       "      <td>42769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>2009</td>\n",
       "      <td>11353.000000</td>\n",
       "      <td>19300.000000</td>\n",
       "      <td>27400.00000</td>\n",
       "      <td>80370.0</td>\n",
       "      <td>73.20</td>\n",
       "      <td>93.346</td>\n",
       "      <td>124746.3936</td>\n",
       "      <td>15.2</td>\n",
       "      <td>2841</td>\n",
       "      <td>NaN</td>\n",
       "      <td>31082.0</td>\n",
       "      <td>1271</td>\n",
       "      <td>NaN</td>\n",
       "      <td>123551</td>\n",
       "      <td>519423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>2010</td>\n",
       "      <td>13191.000000</td>\n",
       "      <td>31200.000000</td>\n",
       "      <td>26020.00000</td>\n",
       "      <td>79850.0</td>\n",
       "      <td>83.75</td>\n",
       "      <td>90.059</td>\n",
       "      <td>135189.7220</td>\n",
       "      <td>12.4</td>\n",
       "      <td>2745</td>\n",
       "      <td>NaN</td>\n",
       "      <td>32839.0</td>\n",
       "      <td>1404</td>\n",
       "      <td>NaN</td>\n",
       "      <td>81117</td>\n",
       "      <td>385456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>2011</td>\n",
       "      <td>13883.000000</td>\n",
       "      <td>24400.000000</td>\n",
       "      <td>26787.22222</td>\n",
       "      <td>20622.5</td>\n",
       "      <td>78.69</td>\n",
       "      <td>106.469</td>\n",
       "      <td>143419.8052</td>\n",
       "      <td>13.6</td>\n",
       "      <td>2538</td>\n",
       "      <td>242800.0</td>\n",
       "      <td>34068.0</td>\n",
       "      <td>1483</td>\n",
       "      <td>98620.0</td>\n",
       "      <td>102899</td>\n",
       "      <td>371826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>2012</td>\n",
       "      <td>12481.000000</td>\n",
       "      <td>25800.000000</td>\n",
       "      <td>26565.00000</td>\n",
       "      <td>19365.0</td>\n",
       "      <td>234.13</td>\n",
       "      <td>136.033</td>\n",
       "      <td>150357.9495</td>\n",
       "      <td>13.7</td>\n",
       "      <td>2551</td>\n",
       "      <td>186598.0</td>\n",
       "      <td>38534.0</td>\n",
       "      <td>2681</td>\n",
       "      <td>112594.0</td>\n",
       "      <td>55814</td>\n",
       "      <td>432055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>2013</td>\n",
       "      <td>14480.000000</td>\n",
       "      <td>28700.000000</td>\n",
       "      <td>22678.33333</td>\n",
       "      <td>19050.0</td>\n",
       "      <td>83.44</td>\n",
       "      <td>108.000</td>\n",
       "      <td>158296.4244</td>\n",
       "      <td>13.4</td>\n",
       "      <td>2456</td>\n",
       "      <td>206513.0</td>\n",
       "      <td>40748.0</td>\n",
       "      <td>1692</td>\n",
       "      <td>83680.0</td>\n",
       "      <td>92834</td>\n",
       "      <td>433650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>2014</td>\n",
       "      <td>10885.000000</td>\n",
       "      <td>24900.000000</td>\n",
       "      <td>26853.33333</td>\n",
       "      <td>20640.0</td>\n",
       "      <td>98.63</td>\n",
       "      <td>112.867</td>\n",
       "      <td>165256.0476</td>\n",
       "      <td>14.2</td>\n",
       "      <td>2526</td>\n",
       "      <td>186124.0</td>\n",
       "      <td>47465.0</td>\n",
       "      <td>1824</td>\n",
       "      <td>69225.0</td>\n",
       "      <td>158371</td>\n",
       "      <td>400712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>2015</td>\n",
       "      <td>10952.000000</td>\n",
       "      <td>26300.000000</td>\n",
       "      <td>27743.33333</td>\n",
       "      <td>21072.5</td>\n",
       "      <td>100.00</td>\n",
       "      <td>100.000</td>\n",
       "      <td>181470.0000</td>\n",
       "      <td>12.5</td>\n",
       "      <td>2684</td>\n",
       "      <td>175906.0</td>\n",
       "      <td>43335.0</td>\n",
       "      <td>1692</td>\n",
       "      <td>64853.0</td>\n",
       "      <td>84679</td>\n",
       "      <td>340353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>2016</td>\n",
       "      <td>15087.000000</td>\n",
       "      <td>30700.000000</td>\n",
       "      <td>26457.77778</td>\n",
       "      <td>21525.0</td>\n",
       "      <td>126.65</td>\n",
       "      <td>107.890</td>\n",
       "      <td>188929.0650</td>\n",
       "      <td>11.9</td>\n",
       "      <td>2616</td>\n",
       "      <td>174056.0</td>\n",
       "      <td>39531.0</td>\n",
       "      <td>1926</td>\n",
       "      <td>60190.0</td>\n",
       "      <td>56372</td>\n",
       "      <td>351826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>2017</td>\n",
       "      <td>18019.000000</td>\n",
       "      <td>33300.000000</td>\n",
       "      <td>27287.77778</td>\n",
       "      <td>22947.5</td>\n",
       "      <td>217.11</td>\n",
       "      <td>192.250</td>\n",
       "      <td>199467.2649</td>\n",
       "      <td>11.6</td>\n",
       "      <td>2638</td>\n",
       "      <td>155606.0</td>\n",
       "      <td>39163.0</td>\n",
       "      <td>2378</td>\n",
       "      <td>58439.0</td>\n",
       "      <td>72460</td>\n",
       "      <td>331612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>2018</td>\n",
       "      <td>16432.000000</td>\n",
       "      <td>32200.000000</td>\n",
       "      <td>27240.00000</td>\n",
       "      <td>24760.0</td>\n",
       "      <td>95.83</td>\n",
       "      <td>160.810</td>\n",
       "      <td>209110.9216</td>\n",
       "      <td>11.8</td>\n",
       "      <td>2745</td>\n",
       "      <td>138899.0</td>\n",
       "      <td>31703.0</td>\n",
       "      <td>1977</td>\n",
       "      <td>58363.0</td>\n",
       "      <td>63402</td>\n",
       "      <td>354172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>2019</td>\n",
       "      <td>18540.000000</td>\n",
       "      <td>25660.000000</td>\n",
       "      <td>29140.00000</td>\n",
       "      <td>18065.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>146.820</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2677</td>\n",
       "      <td>129605.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1438</td>\n",
       "      <td>61612.0</td>\n",
       "      <td>60425</td>\n",
       "      <td>375000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      년도         귤도매가격         귤소매가격      오렌지도매가격  오렌지소매가격  생산자물가지수(감귤)  \\\n",
       "0   1998  10884.666670  11929.333330  21830.00000  45000.0        95.98   \n",
       "1   1999   6206.000000  11933.333330  30530.00000  93240.0       113.29   \n",
       "2   2000   7417.333333  11800.000000  14240.00000  52580.0        58.74   \n",
       "3   2001   6356.000000  11066.666670  17780.00000  51290.0        90.97   \n",
       "4   2002   5312.000000   8866.666667  22410.00000  63440.0        84.83   \n",
       "5   2003   9075.000000  26300.000000  17700.00000  56280.0        57.45   \n",
       "6   2004  12609.000000  27000.000000  18720.00000  58280.0        96.77   \n",
       "7   2005  12133.000000  16500.000000  16700.00000  63520.0       143.35   \n",
       "8   2006  13026.000000  31800.000000  18650.00000  63380.0       100.05   \n",
       "9   2007   7101.000000  13100.000000  23090.00000  70610.0       157.50   \n",
       "10  2008  12719.000000  22100.000000  19320.00000  60350.0        59.02   \n",
       "11  2009  11353.000000  19300.000000  27400.00000  80370.0        73.20   \n",
       "12  2010  13191.000000  31200.000000  26020.00000  79850.0        83.75   \n",
       "13  2011  13883.000000  24400.000000  26787.22222  20622.5        78.69   \n",
       "14  2012  12481.000000  25800.000000  26565.00000  19365.0       234.13   \n",
       "15  2013  14480.000000  28700.000000  22678.33333  19050.0        83.44   \n",
       "16  2014  10885.000000  24900.000000  26853.33333  20640.0        98.63   \n",
       "17  2015  10952.000000  26300.000000  27743.33333  21072.5       100.00   \n",
       "18  2016  15087.000000  30700.000000  26457.77778  21525.0       126.65   \n",
       "19  2017  18019.000000  33300.000000  27287.77778  22947.5       217.11   \n",
       "20  2018  16432.000000  32200.000000  27240.00000  24760.0        95.83   \n",
       "21  2019  18540.000000  25660.000000  29140.00000  18065.0          NaN   \n",
       "\n",
       "    소비자물가지수(감귤)    1인당 가처분소득  1인당 연간소비량(kg)  오렌지가격_1kg  오렌지가공매출_백만원  \\\n",
       "0        80.644   57194.3727            NaN       2310          NaN   \n",
       "1       102.156   58382.7420            NaN       3202          NaN   \n",
       "2        55.410   61964.6448           11.9       1538     188000.0   \n",
       "3        79.033   68150.2896            NaN       1898          NaN   \n",
       "4        84.325   75338.7816           13.3       2390          NaN   \n",
       "5        63.620   82105.3168           13.0       1904          NaN   \n",
       "6        85.198   90825.8304           12.0       2006          NaN   \n",
       "7       106.735   95684.7528           13.1       1814          NaN   \n",
       "8        84.334   99341.6424           12.7       1998          NaN   \n",
       "9       109.137  107368.2552           16.0       2445          NaN   \n",
       "10       67.663  116943.7992           13.0       2066          NaN   \n",
       "11       93.346  124746.3936           15.2       2841          NaN   \n",
       "12       90.059  135189.7220           12.4       2745          NaN   \n",
       "13      106.469  143419.8052           13.6       2538     242800.0   \n",
       "14      136.033  150357.9495           13.7       2551     186598.0   \n",
       "15      108.000  158296.4244           13.4       2456     206513.0   \n",
       "16      112.867  165256.0476           14.2       2526     186124.0   \n",
       "17      100.000  181470.0000           12.5       2684     175906.0   \n",
       "18      107.890  188929.0650           11.9       2616     174056.0   \n",
       "19      192.250  199467.2649           11.6       2638     155606.0   \n",
       "20      160.810  209110.9216           11.8       2745     138899.0   \n",
       "21      146.820          NaN            NaN       2677     129605.0   \n",
       "\n",
       "    오렌지가공량_ton  감귤가격_1kg  감귤가공매출_백만원  감귤가공량_ton   감귤처리량  \n",
       "0      13836.0      1326         NaN       5012  500000  \n",
       "1      15070.0      1512         NaN      33142  567041  \n",
       "2      11375.0       936         NaN      27468  430617  \n",
       "3      10869.0      1194         NaN      47445  527326  \n",
       "4       8229.0      1099         NaN     112359  531081  \n",
       "5      19712.0       900         NaN     120333  477523  \n",
       "6      24065.0      1337         NaN     100517  415338  \n",
       "7      25366.0      1795         NaN     125343  491260  \n",
       "8      26547.0      1426         NaN     109496  450087  \n",
       "9      24101.0      1582         NaN     138782  513746  \n",
       "10     25655.0      1240         NaN      88664   42769  \n",
       "11     31082.0      1271         NaN     123551  519423  \n",
       "12     32839.0      1404         NaN      81117  385456  \n",
       "13     34068.0      1483     98620.0     102899  371826  \n",
       "14     38534.0      2681    112594.0      55814  432055  \n",
       "15     40748.0      1692     83680.0      92834  433650  \n",
       "16     47465.0      1824     69225.0     158371  400712  \n",
       "17     43335.0      1692     64853.0      84679  340353  \n",
       "18     39531.0      1926     60190.0      56372  351826  \n",
       "19     39163.0      2378     58439.0      72460  331612  \n",
       "20     31703.0      1977     58363.0      63402  354172  \n",
       "21         NaN      1438     61612.0      60425  375000  "
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "project = pd.read_csv('predict_consume_최종.csv', encoding='euc-kr')\n",
    "project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [],
   "source": [
    "#project.iloc[:,14]\n",
    "x_1 = project.drop(labels='감귤가공량_ton',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "x = x_1.iloc[:,9:15]\n",
    "y = project.iloc[:,14]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = x.fillna(np.mean(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       5012\n",
       "1      33142\n",
       "2      27468\n",
       "3      47445\n",
       "4     112359\n",
       "5     120333\n",
       "6     100517\n",
       "7     125343\n",
       "8     109496\n",
       "9     138782\n",
       "10     88664\n",
       "11    123551\n",
       "12     81117\n",
       "13    102899\n",
       "14     55814\n",
       "15     92834\n",
       "16    158371\n",
       "17     84679\n",
       "18     56372\n",
       "19     72460\n",
       "20     63402\n",
       "21     60425\n",
       "Name: 감귤가공량_ton, dtype: int64"
      ]
     },
     "execution_count": 306,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [],
   "source": [
    "pro2 = project.fillna(np.mean(project))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정확도:81.82 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "#model.fit(pro2_x,pro2_y)\n",
    "logreg= LogisticRegression(solver='lbfgs',max_iter=20).fit(x,y)\n",
    "\n",
    "print('정확도:%.2f'%(logreg.score(x,y)*100),\"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [],
   "source": [
    "pro2.head()\n",
    "pro2_x = pro2.iloc[:,:15]\n",
    "pro2_y = pro2.iloc[:,15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     500000\n",
       "13    371826\n",
       "8     450087\n",
       "1     567041\n",
       "15    433650\n",
       "Name: 감귤처리량, dtype: int64"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(x,y,test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정확도:100.00 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\82105\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "C:\\Users\\82105\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\82105\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\82105\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\82105\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\82105\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\82105\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\82105\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\82105\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\82105\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\82105\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\82105\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\82105\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\82105\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\82105\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\82105\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\82105\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\82105\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\82105\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\82105\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\82105\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\82105\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\82105\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "model = LogisticRegression(solver='lbfgs',max_iter=20)\n",
    "#model.fit(pro2_x,pro2_y)\n",
    "logreg= LogisticRegression(solver='lbfgs',max_iter=20).fit(pro2_x,pro2_y)\n",
    "\n",
    "print('정확도:%.2f'%(logreg.score(pro2_x,pro2_y)*100),\"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "감귤처리량          0.195746\n",
      "오렌지가격_1kg      0.195238\n",
      "감귤가격_1kg       0.194451\n",
      "오렌지가공량_ton     0.194315\n",
      "오렌지가공매출_백만원    0.114597\n",
      "감귤가공매출_백만원     0.105653\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "model = RandomForestClassifier(n_estimators=100)\n",
    "model.fit(x,y)\n",
    "\n",
    "# y_pred = model.predict(x_test)\n",
    "\n",
    "# print('RandomForestClassifier test 정확도:%.2f'%(model_score(pro2_x,pro2_y)*100),\"%\")\n",
    "\n",
    "\n",
    "features = pd.Series(model.feature_importances_,\n",
    "                    index=x.columns).sort_values(ascending=False)\n",
    "print(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForest test 정확도:88.70 %\n"
     ]
    }
   ],
   "source": [
    "model = RandomForestRegressor(n_estimators=100, bootstrap=True, criterion='mse', max_depth=None, max_leaf_nodes=None, min_samples_split=2, min_samples_leaf=1, max_features='auto')\n",
    "model.fit(x, y)\n",
    "\n",
    "print('RandomForest test 정확도:%.2f'%(model.score(x, y)*100),\"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정확도:50.00 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# MinMaxScaler + LogisticRegression\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler(feature_range=(0,1))\n",
    "scaled_data = scaler.fit_transform(x)\n",
    "\n",
    "logreg= LogisticRegression(solver='lbfgs',max_iter=20).fit(scaled_data,y)\n",
    "\n",
    "print('정확도:%.2f'%(logreg.score(scaled_data,y)*100),\"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정확도:81.83 %\n"
     ]
    }
   ],
   "source": [
    "# Random\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "scaler = MinMaxScaler(feature_range=(0,1))\n",
    "scaled_data = scaler.fit_transform(x)\n",
    "\n",
    "randomF= RandomForestRegressor(n_estimators=100,max_depth =3,min_samples_leaf=1).fit(scaled_data,y)\n",
    "\n",
    "print('정확도:%.2f'%(randomF.score(scaled_data,y)*100),\"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logi.Regre Z점수 정확도:90.91 %\n",
      "Logi.Regre maxabs점수 정확도:50.00 %\n",
      "Logi.Regre minmax점수 정확도:50.00 %\n",
      "Logi.Regre robust점수 정확도:22.73 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# z점수\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import scale, robust_scale, minmax_scale , maxabs_scale\n",
    "scaler = scale(x)\n",
    "\n",
    "#scaled_data = scale.fit(x)\n",
    "\n",
    "logreg= LogisticRegression(solver='lbfgs',max_iter=20).fit(scaler,y)\n",
    "\n",
    "print(\"Logi.Regre Z점수 정확도:%.2f\" %(logreg.score(scaler,y)*100),\"%\")\n",
    "#\n",
    "scaler = maxabs_scale(x)\n",
    "\n",
    "#scaled_data = scale.fit(x)\n",
    "\n",
    "logreg= LogisticRegression(solver='lbfgs',max_iter=20).fit(scaler,y)\n",
    "\n",
    "print('Logi.Regre maxabs점수 정확도:%.2f'%(logreg.score(scaler,y)*100),\"%\")\n",
    "#\n",
    "scaler = minmax_scale(x)\n",
    "\n",
    "#scaled_data = scale.fit(x)\n",
    "\n",
    "logreg= LogisticRegression(solver='lbfgs',max_iter=20).fit(scaler,y)\n",
    "\n",
    "print('Logi.Regre minmax점수 정확도:%.2f'%(logreg.score(scaler,y)*100),\"%\")\n",
    "#\n",
    "scaler = robust_scale(x)\n",
    "\n",
    "#scaled_data = scale.fit(x)\n",
    "\n",
    "logreg= LogisticRegression(solver='lbfgs',max_iter=20).fit(scaler,y)\n",
    "\n",
    "print('Logi.Regre robust점수 정확도:%.2f'%(logreg.score(scaler,y)*100),\"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (22,6) (22,) ",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-338-3ed8ef4f96f0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mscaler\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mscale\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0msns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjointplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscaler\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\seaborn\\axisgrid.py\u001b[0m in \u001b[0;36mjointplot\u001b[1;34m(x, y, data, kind, stat_func, color, height, ratio, space, dropna, xlim, ylim, joint_kws, marginal_kws, annot_kws, **kwargs)\u001b[0m\n\u001b[0;32m   2282\u001b[0m     grid = JointGrid(x, y, data, dropna=dropna,\n\u001b[0;32m   2283\u001b[0m                      \u001b[0mheight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mheight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mratio\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mratio\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mspace\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mspace\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2284\u001b[1;33m                      xlim=xlim, ylim=ylim)\n\u001b[0m\u001b[0;32m   2285\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2286\u001b[0m     \u001b[1;31m# Plot the data using the grid\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\seaborn\\axisgrid.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, x, y, data, height, ratio, space, dropna, xlim, ylim, size)\u001b[0m\n\u001b[0;32m   1723\u001b[0m         \u001b[1;31m# Possibly drop NA\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1724\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mdropna\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1725\u001b[1;33m             \u001b[0mnot_na\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnotnull\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_array\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m&\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnotnull\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_array\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1726\u001b[0m             \u001b[0mx_array\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx_array\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnot_na\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1727\u001b[0m             \u001b[0my_array\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0my_array\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnot_na\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: operands could not be broadcast together with shapes (22,6) (22,) "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:211: RuntimeWarning: Glyph 44048 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:211: RuntimeWarning: Glyph 44516 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:211: RuntimeWarning: Glyph 44032 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:211: RuntimeWarning: Glyph 44277 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:211: RuntimeWarning: Glyph 47049 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:180: RuntimeWarning: Glyph 44048 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:180: RuntimeWarning: Glyph 44516 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:180: RuntimeWarning: Glyph 44032 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:180: RuntimeWarning: Glyph 44277 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:180: RuntimeWarning: Glyph 47049 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x432 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "scaler = scale(x)\n",
    "\n",
    "sns.jointplot(scaler, y)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'LinearRegression' object has no attribute 'summary'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-336-7b24379fe9a4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mmodel_boston\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcoef_\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel_boston\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'LinearRegression' object has no attribute 'summary'"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "model_boston = LinearRegression().fit(scaler, y)\n",
    "model_boston.coef_\n",
    "\n",
    "print(model_boston.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logi.Regre Z점수 정확도:90.91 %\n",
      "[[ 1.28027135e-02 -5.73383617e-03 -5.76023749e-01 -8.17184594e-02\n",
      "   2.54961803e-04  2.73838123e-01]\n",
      " [-9.02603767e-01  2.46798420e-01 -5.02017950e-01 -5.00953398e-01\n",
      "  -3.06582633e-02 -5.87349231e-02]\n",
      " [ 1.02453332e+00  5.07583369e-02 -5.38369508e-01  4.67041811e-02\n",
      "  -3.85429165e-03  5.72305211e-01]\n",
      " [-4.74190968e-01 -6.40292669e-02 -6.01183340e-01 -1.46249027e-01\n",
      "  -2.05790303e-03  4.78701940e-01]\n",
      " [ 6.26083801e-02 -7.54820659e-02  1.74111919e-01  7.61211017e-01\n",
      "   8.99382203e-01  5.73430003e-02]\n",
      " [ 1.67040058e-01  1.50053748e-01  3.90882946e-01  3.04982817e-01\n",
      "  -6.05813586e-01 -2.03949796e-01]\n",
      " [ 2.52828600e-01 -1.09726889e+00 -4.98834247e-02 -3.54005980e-01\n",
      "  -2.92696116e-01 -1.17282509e-01]\n",
      " [ 3.10663966e-01 -7.59012327e-01 -3.72442115e-02  3.83951891e-01\n",
      "  -4.45247090e-01 -1.75002864e-01]\n",
      " [ 9.18932946e-02 -2.94809623e-01  2.80342717e-01  8.98171581e-01\n",
      "  -5.20913692e-01 -2.71546706e-01]\n",
      " [ 5.28914242e-01 -9.18097399e-03  2.33329987e-01 -3.68097953e-01\n",
      "   5.90769641e-02 -1.79976627e-01]\n",
      " [ 3.27382944e-01  7.06238811e-02  6.95687457e-01 -8.32846600e-02\n",
      "  -3.57419270e-01 -2.85991588e-01]\n",
      " [-2.40168592e-01 -2.86915521e-03 -9.98837374e-02 -2.39646712e-01\n",
      "   4.26656385e-02 -1.20886173e+00]\n",
      " [-2.69668873e-02  5.20336547e-01  6.12236198e-01  2.24090450e-02\n",
      "   1.20196360e-01  1.93386684e-01]\n",
      " [-4.52600506e-01 -5.04158425e-02 -8.10855069e-03 -1.55856327e-01\n",
      "   7.75047909e-03 -3.47688068e-02]\n",
      " [ 1.49575566e-01  1.07498959e+00  9.86203004e-02 -2.04767511e-01\n",
      "   5.34540662e-01 -1.77089343e-01]\n",
      " [-5.20163759e-01 -5.44986202e-02  1.33809726e-01 -6.13789512e-02\n",
      "  -1.01397268e-02  1.60372820e-01]\n",
      " [ 1.75289688e-01 -1.43546763e-02 -8.05809668e-01 -4.21626464e-01\n",
      "   1.12132383e-02  3.80240057e-01]\n",
      " [-4.44321553e-01 -8.71022836e-02 -3.74416024e-03 -7.81100116e-01\n",
      "   9.54575395e-03  2.38890315e-01]\n",
      " [ 5.94585925e-01 -2.78000698e-02  3.47819895e-01 -5.16030553e-01\n",
      "   2.28256705e-02  5.44676630e-01]\n",
      " [-8.60990238e-01 -2.73141068e-02  2.04386246e-03  5.31162380e-01\n",
      "  -1.06728082e-01  4.09688293e-01]\n",
      " [ 5.76936539e-02  5.28920121e-03 -1.04193394e-01  1.26684066e-01\n",
      "  -4.38165982e-02  5.12601990e-01]\n",
      " [ 6.55158743e-04  2.42902371e-01  9.46551562e-01  1.28327493e-01\n",
      "  -2.70825243e-01  7.78718596e-02]] \n",
      "\n",
      "\n",
      " [-3.31972116 -4.14706339 -3.79477098 -3.70600073 -4.27957841 -3.47147444\n",
      " -3.82041441 -3.87685648 -4.02832721 -3.17826421 -3.4960573  -4.04827451\n",
      " -3.42710613 -3.18078921 -4.22612472 -3.15908507 -3.71226212 -3.54973462\n",
      " -3.32765992 -3.34740699 -3.15279665 -3.50378426]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "scaler = scale(x)\n",
    "logreg= LogisticRegression(solver='lbfgs',max_iter=20).fit(scaler,y)\n",
    "\n",
    "print(\"Logi.Regre Z점수 정확도:%.2f\" %(logreg.score(scaler,y)*100),\"%\")\n",
    "\n",
    "print(logreg.coef_,'\\n\\n\\n', logreg.intercept_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RF/ Z_점수 정확도:85.21 %\n",
      "RF/ robust 정확도:85.21 %\n",
      "RF/ minmax 정확도:85.21 %\n",
      "RF/ maxabs 정확도:85.21 %\n"
     ]
    }
   ],
   "source": [
    "# Random forest scale\n",
    "from sklearn.ensemble import RandomForestRegressor,RandomForestClassifier\n",
    "from sklearn.preprocessing import scale, robust_scale, minmax_scale , maxabs_scale\n",
    "scaler = scale(x)\n",
    "\n",
    "RandomF= RandomForestRegressor(n_estimators = 100, random_state=42).fit(scaler,y)\n",
    "\n",
    "print('RF/ Z_점수 정확도:%.2f'%(RandomF.score(scaler,y)*100),\"%\")\n",
    "###########\n",
    "scaler = robust_scale(x)\n",
    "\n",
    "RandomF= RandomForestRegressor(n_estimators = 100, random_state=42).fit(scaler,y)\n",
    "\n",
    "print('RF/ robust 정확도:%.2f'%(RandomF.score(scaler,y)*100),\"%\")\n",
    "###########\n",
    "scaler = minmax_scale(x)\n",
    "\n",
    "RandomF= RandomForestRegressor(n_estimators = 100, random_state=42).fit(scaler,y)\n",
    "\n",
    "print('RF/ minmax 정확도:%.2f'%(RandomF.score(scaler,y)*100),\"%\")\n",
    "###########\n",
    "scaler = maxabs_scale(x)\n",
    "\n",
    "RandomF= RandomForestRegressor(n_estimators = 100, random_state=42).fit(scaler,y)\n",
    "\n",
    "print('RF/ maxabs 정확도:%.2f'%(RandomF.score(scaler,y)*100),\"%\")\n",
    "###########"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor,RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier,KNeighborsRegressor\n",
    "from sklearn.tree import DecisionTreeClassifier,DecisionTreeRegressor\n",
    "from sklearn.svm import LinearSVR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM: -1700.40%\n",
      "DecisionTreeRegressor: -2907.46%\n",
      "KNeighborsRegressor: -442.04%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression: 0.00%\n",
      "RandomForestRegressor: -1200.20%\n"
     ]
    }
   ],
   "source": [
    "models = {\n",
    "    'SVM':LinearSVR(epsilon=1.5,random_state=42),\n",
    "    'DecisionTreeRegressor':DecisionTreeRegressor(),\n",
    "    'KNeighborsRegressor': KNeighborsRegressor(),\n",
    "    'LogisticRegression': LogisticRegression(solver='lbfgs', max_iter=2000),\n",
    "    'RandomForestRegressor': RandomForestRegressor(n_estimators=100)\n",
    "}\n",
    "\n",
    "cv = KFold(n_splits=5, random_state=42)\n",
    "\n",
    "for name, model in models.items():\n",
    "    scores = cross_val_score(model, x, y, cv=cv)\n",
    "    print('%s: %.2f%%'% (name, np.mean(scores)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM: 0.00%\n",
      "SVM: 0.00 %\n",
      "DecisionTreeClassifier: 0.00%\n",
      "DecisionTreeClassifier: 0.00 %\n",
      "KNeighborsClassifier: 0.00%\n",
      "KNeighborsClassifier: 0.00 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression: 0.00%\n",
      "LogisticRegression: 0.00 %\n",
      "RandomForestClassifier: 0.00%\n",
      "RandomForestClassifier: 0.00 %\n"
     ]
    }
   ],
   "source": [
    "models = {\n",
    "    'SVM':svm.SVC(gamma='scale'),\n",
    "    'DecisionTreeClassifier':DecisionTreeClassifier(),\n",
    "    'KNeighborsClassifier': KNeighborsClassifier(),\n",
    "    'LogisticRegression': LogisticRegression(solver='lbfgs', max_iter=2000),\n",
    "    'RandomForestClassifier': RandomForestClassifier(n_estimators=100)\n",
    "}\n",
    "\n",
    "cv = KFold(n_splits=5, random_state=42)\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "for name, model in models.items():\n",
    "    scores = cross_val_score(model, X_train, y_train, cv=cv)\n",
    "    print('%s: %.2f%%'% (name, np.mean(scores)*100))\n",
    "    print('%s: %.2f'%(name,metrics.accuracy_score(y_pred, y_test)*100),\"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM 정확도:0.00 %\n"
     ]
    }
   ],
   "source": [
    "model = svm.SVC(gamma='scale')\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "print('SVM 정확도:%.2f'%(metrics.accuracy_score(y_pred, y_test)*100),\"%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
