{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4일차\n",
    "# CNN은 주변을고려해서 특성\n",
    "# RNN은 순서적으로 고려해서 특성을 만듦\n",
    "# http://blog.naver.com/PostView.nhn?blogId=magnking&logNo=221323257045&redirect=Dlog&widgetTypeCall=true&directAccess=false"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Entity <bound method BasicRNNCell.call of <tensorflow.python.ops.rnn_cell_impl.BasicRNNCell object at 0x0000020A9869AF08>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BasicRNNCell.call of <tensorflow.python.ops.rnn_cell_impl.BasicRNNCell object at 0x0000020A9869AF08>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method BasicRNNCell.call of <tensorflow.python.ops.rnn_cell_impl.BasicRNNCell object at 0x0000020A9869AF08>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BasicRNNCell.call of <tensorflow.python.ops.rnn_cell_impl.BasicRNNCell object at 0x0000020A9869AF08>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method BasicRNNCell.call of <tensorflow.python.ops.rnn_cell_impl.BasicRNNCell object at 0x0000020A9869AF08>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BasicRNNCell.call of <tensorflow.python.ops.rnn_cell_impl.BasicRNNCell object at 0x0000020A9869AF08>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method BasicRNNCell.call of <tensorflow.python.ops.rnn_cell_impl.BasicRNNCell object at 0x0000020A9869AF08>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BasicRNNCell.call of <tensorflow.python.ops.rnn_cell_impl.BasicRNNCell object at 0x0000020A9869AF08>>: AssertionError: Bad argument number for Name: 3, expecting 4\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import tensorflow as tf\n",
    "tf.reset_default_graph() # 그라프 초기화 ( 변수 생성 )\n",
    "n_inputs = 3  # 입력 데이터\n",
    "n_neurons = 5 # 셀의 가중치 사이즈\n",
    "X0 = tf.placeholder(tf.float32,[None,n_inputs]) # 4*3\n",
    "X1 = tf.placeholder(tf.float32,[None,n_inputs]) # 4*3\n",
    "# [0,1,2] 사이즈가 하나의 셀로 입력\n",
    "# FFNN(feed forword neural network)\n",
    "basic_cell = tf.contrib.rnn.BasicRNNCell(num_units=n_neurons) # 가중치 사이즈\n",
    "# 가중치 사이즈 -> 특성을 찾아내는 것\n",
    "# static_rnn -> rnn network : 4개의 셀이 연결되면서 메모리 확보\n",
    "output_seqs, state = tf.contrib.rnn.static_rnn(basic_cell,[X0,X1],dtype=tf.float32) \n",
    "# 2*4*3 / 배치사이즈 * 셀수 * 뉴런수\n",
    "Y0,Y1 = output_seqs\n",
    "# 출력, 다음 셀로 전달되는 값 : 마지막 state값\n",
    "# (수평으로 셀을 연경해주는 값)\n",
    "init=tf.global_variables_initializer()\n",
    "X0_batch = np.array([[0,1,2],[3,4,5],[6,7,8],[9,0,1]])\n",
    "X1_batch = np.array([[9,8,7],[0,0,0],[6,5,4],[3,2,1]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "처음 데이터 특성 :  [[-0.91036344 -0.34917507 -0.33427748  0.7234802   0.93172115]\n",
      " [-0.99857163  0.9400998  -0.99443424  0.6079991   0.9989562 ]\n",
      " [-0.9999783   0.99908066 -0.9999689   0.45941737  0.9999846 ]\n",
      " [ 0.63038296  0.99985343 -0.9999628  -0.9999395  -0.97653687]] 차수 : (4, 5)\n",
      "두번째 데이터 특성 :  [[-0.9999015   0.9999997  -0.9999995  -0.47917116  0.9998768 ]\n",
      " [ 0.6208438   0.7797957  -0.7517404   0.9352928  -0.37674925]\n",
      " [-0.9537268   0.99997634 -0.99998343  0.3216574   0.9678108 ]\n",
      " [ 0.5986795   0.98501164 -0.9955096  -0.80658996  0.16454647]] 차수 : (4, 5)\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    Y0_val,Y1_val = sess.run([Y0,Y1], feed_dict={X0:X0_batch, X1:X1_batch})\n",
    "\n",
    "print(\"처음 데이터 특성 : \", Y0_val,\"차수 :\", Y0_val.shape)\n",
    "print(\"두번째 데이터 특성 : \", Y1_val,\"차수 :\", Y1_val.shape)\n",
    "# 4*3 -> 4*5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    " # 셀이 가지고 있는 가중치 사이즈는? 3*5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph() # 그라프 초기화 ( 변수 생성 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Entity <bound method BasicRNNCell.call of <tensorflow.python.ops.rnn_cell_impl.BasicRNNCell object at 0x0000020A9969BFC8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BasicRNNCell.call of <tensorflow.python.ops.rnn_cell_impl.BasicRNNCell object at 0x0000020A9969BFC8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method BasicRNNCell.call of <tensorflow.python.ops.rnn_cell_impl.BasicRNNCell object at 0x0000020A9969BFC8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BasicRNNCell.call of <tensorflow.python.ops.rnn_cell_impl.BasicRNNCell object at 0x0000020A9969BFC8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x0000020A99B8F188>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x0000020A99B8F188>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x0000020A99B8F188>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x0000020A99B8F188>>: AssertionError: Bad argument number for Name: 3, expecting 4\n"
     ]
    }
   ],
   "source": [
    "n_steps =28 # sell이 28\n",
    "n_inputs = 28 # sell당 input size\n",
    "n_neurons = 150 # 뉴런  150개\n",
    "n_outputs = 10 # output 10개 확률사이즈\n",
    "learning_rate = 0.001\n",
    "# 3차원으로\n",
    "X = tf.placeholder(tf.float32, [None, n_steps, n_inputs]) # 3차원임\n",
    "y = tf.placeholder(tf.int32, [None])\n",
    "# 하나의 셀은 FFNN 임\n",
    "basic_cell = tf.contrib.rnn.BasicRNNCell(num_units=n_neurons)\n",
    "output, states = tf.nn.dynamic_rnn(basic_cell, X, dtype=tf.float32) # 150개의 히든레이어\n",
    "# 셀 : 28개\n",
    "# state 마지막 셀의 수평으로 전달되는 값\n",
    "# state는 마지막 셀의 output과 동일\n",
    "# 28개의 셀이 있는데 마지막 1개의 output사용 -> many to one (감정분류)-> 분류기\n",
    "# state의 차수 : 150 * 150 \n",
    "# output의 차수 : latent time 지연시간을 통해 계산된 셀의\n",
    "# 모든 값을 결합 출력 150*28*150\n",
    "# 150개의 특징중에 10개만 출력\n",
    "logits = tf.layers.dense(states, n_outputs) # 입력차수와 출력차수만 정해주면 자동으로 바이어스 생성\n",
    "# 가중치 공간을 확보해서 계산해줌\n",
    "#150 x 150 = 150 x 10\n",
    "# 가중치 사이즈는 150  10 \n",
    "xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y, logits=logits) # 분류를 위한 미분이 가능한식\n",
    "loss = tf.reduce_mean(xentropy) # 배치 사이즈 -> 평균\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate= learning_rate)# momentum + propgrad\n",
    "training_op = optimizer.minimize(loss)\n",
    "correct = tf.nn.in_top_k(logits,y,1) # 양쪽으로 비교해서 큰놈으로\n",
    "accuracy = tf.reduce_mean(tf.cast(correct, tf.float32))\n",
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-24-9aff0e2313ad>:2: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From C:\\Users\\ICT01_22\\Anaconda3\\envs\\tf_test\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "WARNING:tensorflow:From C:\\Users\\ICT01_22\\Anaconda3\\envs\\tf_test\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting /tmp/data/train-images-idx3-ubyte.gz\n",
      "WARNING:tensorflow:From C:\\Users\\ICT01_22\\Anaconda3\\envs\\tf_test\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting /tmp/data/train-labels-idx1-ubyte.gz\n",
      "Extracting /tmp/data/t10k-images-idx3-ubyte.gz\n",
      "Extracting /tmp/data/t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From C:\\Users\\ICT01_22\\Anaconda3\\envs\\tf_test\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"/tmp/data/\")\n",
    "X_test = mnist.test.images.reshape((-1, n_steps, n_inputs))\n",
    "y_test = mnist.test.labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 train accuracy: 0.94666666 test acuuracy : 0.927\n",
      "1 train accuracy: 0.94666666 test acuuracy : 0.9437\n",
      "2 train accuracy: 0.97333336 test acuuracy : 0.9533\n",
      "3 train accuracy: 0.97333336 test acuuracy : 0.9604\n",
      "4 train accuracy: 0.9533333 test acuuracy : 0.958\n",
      "5 train accuracy: 0.98 test acuuracy : 0.9688\n",
      "6 train accuracy: 0.9866667 test acuuracy : 0.9699\n",
      "7 train accuracy: 0.9866667 test acuuracy : 0.9713\n",
      "8 train accuracy: 0.98 test acuuracy : 0.9749\n",
      "9 train accuracy: 0.99333334 test acuuracy : 0.9739\n",
      "10 train accuracy: 0.9866667 test acuuracy : 0.9694\n",
      "11 train accuracy: 0.99333334 test acuuracy : 0.9714\n",
      "12 train accuracy: 0.9866667 test acuuracy : 0.9717\n",
      "13 train accuracy: 0.98 test acuuracy : 0.9741\n",
      "14 train accuracy: 0.97333336 test acuuracy : 0.975\n",
      "15 train accuracy: 0.96666664 test acuuracy : 0.9752\n",
      "16 train accuracy: 0.99333334 test acuuracy : 0.9706\n",
      "17 train accuracy: 0.97333336 test acuuracy : 0.9748\n",
      "18 train accuracy: 0.98 test acuuracy : 0.9749\n",
      "19 train accuracy: 0.99333334 test acuuracy : 0.9754\n",
      "20 train accuracy: 0.99333334 test acuuracy : 0.9786\n",
      "21 train accuracy: 1.0 test acuuracy : 0.9752\n",
      "22 train accuracy: 0.99333334 test acuuracy : 0.9665\n",
      "23 train accuracy: 0.99333334 test acuuracy : 0.9798\n",
      "24 train accuracy: 0.99333334 test acuuracy : 0.9765\n",
      "25 train accuracy: 0.9866667 test acuuracy : 0.9763\n",
      "26 train accuracy: 0.99333334 test acuuracy : 0.9786\n",
      "27 train accuracy: 0.99333334 test acuuracy : 0.9743\n",
      "28 train accuracy: 0.99333334 test acuuracy : 0.9768\n",
      "29 train accuracy: 0.99333334 test acuuracy : 0.9769\n",
      "30 train accuracy: 0.99333334 test acuuracy : 0.9803\n",
      "31 train accuracy: 0.99333334 test acuuracy : 0.9742\n",
      "32 train accuracy: 0.98 test acuuracy : 0.9786\n",
      "33 train accuracy: 0.98 test acuuracy : 0.9693\n",
      "34 train accuracy: 0.9866667 test acuuracy : 0.9715\n",
      "35 train accuracy: 0.9866667 test acuuracy : 0.9788\n",
      "36 train accuracy: 0.9866667 test acuuracy : 0.9786\n",
      "37 train accuracy: 0.99333334 test acuuracy : 0.9784\n",
      "38 train accuracy: 0.9866667 test acuuracy : 0.9785\n",
      "39 train accuracy: 0.9866667 test acuuracy : 0.9784\n",
      "40 train accuracy: 0.99333334 test acuuracy : 0.9778\n",
      "41 train accuracy: 0.99333334 test acuuracy : 0.9774\n",
      "42 train accuracy: 1.0 test acuuracy : 0.9772\n",
      "43 train accuracy: 1.0 test acuuracy : 0.9781\n",
      "44 train accuracy: 0.98 test acuuracy : 0.9772\n",
      "45 train accuracy: 0.9866667 test acuuracy : 0.9783\n",
      "46 train accuracy: 0.99333334 test acuuracy : 0.9779\n",
      "47 train accuracy: 0.9866667 test acuuracy : 0.9734\n",
      "48 train accuracy: 1.0 test acuuracy : 0.98\n",
      "49 train accuracy: 0.99333334 test acuuracy : 0.9734\n",
      "50 train accuracy: 0.98 test acuuracy : 0.9739\n",
      "51 train accuracy: 0.9866667 test acuuracy : 0.9791\n",
      "52 train accuracy: 0.9866667 test acuuracy : 0.9761\n",
      "53 train accuracy: 1.0 test acuuracy : 0.9781\n",
      "54 train accuracy: 0.99333334 test acuuracy : 0.9782\n",
      "55 train accuracy: 0.9866667 test acuuracy : 0.9731\n",
      "56 train accuracy: 1.0 test acuuracy : 0.9792\n",
      "57 train accuracy: 0.99333334 test acuuracy : 0.9784\n",
      "58 train accuracy: 0.99333334 test acuuracy : 0.9781\n",
      "59 train accuracy: 0.99333334 test acuuracy : 0.9796\n",
      "60 train accuracy: 0.99333334 test acuuracy : 0.9797\n",
      "61 train accuracy: 1.0 test acuuracy : 0.9761\n",
      "62 train accuracy: 0.99333334 test acuuracy : 0.9781\n",
      "63 train accuracy: 0.99333334 test acuuracy : 0.9774\n",
      "64 train accuracy: 0.99333334 test acuuracy : 0.979\n",
      "65 train accuracy: 0.9866667 test acuuracy : 0.9784\n",
      "66 train accuracy: 0.9866667 test acuuracy : 0.9787\n",
      "67 train accuracy: 1.0 test acuuracy : 0.9806\n",
      "68 train accuracy: 0.99333334 test acuuracy : 0.976\n",
      "69 train accuracy: 1.0 test acuuracy : 0.9759\n",
      "70 train accuracy: 1.0 test acuuracy : 0.9713\n",
      "71 train accuracy: 0.99333334 test acuuracy : 0.9774\n",
      "72 train accuracy: 1.0 test acuuracy : 0.9804\n",
      "73 train accuracy: 0.9866667 test acuuracy : 0.9742\n",
      "74 train accuracy: 1.0 test acuuracy : 0.9798\n",
      "75 train accuracy: 1.0 test acuuracy : 0.9782\n",
      "76 train accuracy: 1.0 test acuuracy : 0.9803\n",
      "77 train accuracy: 1.0 test acuuracy : 0.9781\n",
      "78 train accuracy: 1.0 test acuuracy : 0.9781\n",
      "79 train accuracy: 0.99333334 test acuuracy : 0.9768\n",
      "80 train accuracy: 0.9866667 test acuuracy : 0.9757\n",
      "81 train accuracy: 1.0 test acuuracy : 0.9772\n",
      "82 train accuracy: 1.0 test acuuracy : 0.9763\n",
      "83 train accuracy: 1.0 test acuuracy : 0.9814\n",
      "84 train accuracy: 0.9866667 test acuuracy : 0.9772\n",
      "85 train accuracy: 0.9866667 test acuuracy : 0.9733\n",
      "86 train accuracy: 1.0 test acuuracy : 0.9767\n",
      "87 train accuracy: 0.99333334 test acuuracy : 0.9747\n",
      "88 train accuracy: 0.99333334 test acuuracy : 0.9793\n",
      "89 train accuracy: 1.0 test acuuracy : 0.9761\n",
      "90 train accuracy: 0.9866667 test acuuracy : 0.9763\n",
      "91 train accuracy: 0.9866667 test acuuracy : 0.9733\n",
      "92 train accuracy: 0.98 test acuuracy : 0.9758\n",
      "93 train accuracy: 0.99333334 test acuuracy : 0.9775\n",
      "94 train accuracy: 0.9866667 test acuuracy : 0.978\n",
      "95 train accuracy: 0.99333334 test acuuracy : 0.9788\n",
      "96 train accuracy: 1.0 test acuuracy : 0.9785\n",
      "97 train accuracy: 0.98 test acuuracy : 0.9826\n",
      "98 train accuracy: 0.9866667 test acuuracy : 0.9759\n",
      "99 train accuracy: 1.0 test acuuracy : 0.9792\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 100\n",
    "batch_size = 150\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    for epoch in range(n_epochs):\n",
    "        for iteration in range(mnist.train.num_examples // batch_size): # 20000*150 돌고 그담에 epoch 만큼 더돌림\n",
    "            X_batch, y_batch = mnist.train.next_batch(batch_size)\n",
    "            # 이미지 사이즈로 생성\n",
    "            X_batch = X_batch.reshape((-1, n_steps, n_inputs))\n",
    "            sess.run(training_op, feed_dict={X: X_batch,\n",
    "                                            y:y_batch})\n",
    "        acc_train = accuracy.eval(feed_dict={X:X_batch,\n",
    "                                            y:y_batch})\n",
    "        acc_test = accuracy.eval(feed_dict={X:X_test,\n",
    "                                           y:y_test})\n",
    "        print(epoch, \"train accuracy:\", acc_train,\n",
    "             \"test acuuracy :\", acc_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ICT01_22\\Anaconda3\\envs\\tf_test\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\ICT01_22\\Anaconda3\\envs\\tf_test\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\ICT01_22\\Anaconda3\\envs\\tf_test\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\ICT01_22\\Anaconda3\\envs\\tf_test\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\ICT01_22\\Anaconda3\\envs\\tf_test\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\ICT01_22\\Anaconda3\\envs\\tf_test\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "C:\\Users\\ICT01_22\\Anaconda3\\envs\\tf_test\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\ICT01_22\\Anaconda3\\envs\\tf_test\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\ICT01_22\\Anaconda3\\envs\\tf_test\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\ICT01_22\\Anaconda3\\envs\\tf_test\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\ICT01_22\\Anaconda3\\envs\\tf_test\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\ICT01_22\\Anaconda3\\envs\\tf_test\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import tensorflow as tf\n",
    "def reset_graph(seed=42):\n",
    "    tf.reset_default_graph()\n",
    "    tf.set_random_seed(seed)\n",
    "    np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-4-f718a4967771>:15: BasicRNNCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This class is equivalent as tf.keras.layers.SimpleRNNCell, and will be replaced by that in Tensorflow 2.0.\n",
      "WARNING:tensorflow:From <ipython-input-4-f718a4967771>:17: MultiRNNCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This class is equivalent as tf.keras.layers.StackedRNNCells, and will be replaced by that in Tensorflow 2.0.\n"
     ]
    }
   ],
   "source": [
    "# BasicRNNCell\n",
    "# MultiRNNCell : 수직으로 레이어 구성\n",
    "# dynamic_rnn : 모델\n",
    "\n",
    "reset_graph()\n",
    "n_steps = 28\n",
    "n_inputs = 28\n",
    "n_outputs = 10\n",
    "learning_rate = 0.001\n",
    "X = tf.placeholder(tf.float32, [None, n_steps,n_inputs])\n",
    "y = tf.placeholder(tf.int32,[None])\n",
    "n_neurons = 100\n",
    "n_layers = 3 # 3개의 멀티 레이어 : 3개의 셀을 생성\n",
    "layers = [tf.contrib.rnn.BasicRNNCell(num_units=n_neurons,activation = tf.nn.relu)\n",
    "         for layer in range(n_layers)]\n",
    "# 3개의 셀을 조합해서 MultiRNNCell\n",
    "multi_layer_cell = tf.contrib.rnn.MultiRNNCell(layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /tmp/data/train-images-idx3-ubyte.gz\n",
      "Extracting /tmp/data/train-labels-idx1-ubyte.gz\n",
      "Extracting /tmp/data/t10k-images-idx3-ubyte.gz\n",
      "Extracting /tmp/data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"/tmp/data/\")\n",
    "X_test = mnist.test.images.reshape((-1, n_steps, n_inputs))\n",
    "y_test = mnist.test.labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-6-f15a440fa410>:5: dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `keras.layers.RNN(cell)`, which is equivalent to this API\n",
      "WARNING:tensorflow:Entity <bound method MultiRNNCell.call of <tensorflow.python.ops.rnn_cell_impl.MultiRNNCell object at 0x0000024BE549A9C8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiRNNCell.call of <tensorflow.python.ops.rnn_cell_impl.MultiRNNCell object at 0x0000024BE549A9C8>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <bound method MultiRNNCell.call of <tensorflow.python.ops.rnn_cell_impl.MultiRNNCell object at 0x0000024BE549A9C8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiRNNCell.call of <tensorflow.python.ops.rnn_cell_impl.MultiRNNCell object at 0x0000024BE549A9C8>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:From C:\\Users\\ICT01_22\\Anaconda3\\envs\\tf_test\\lib\\site-packages\\tensorflow\\python\\ops\\init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From C:\\Users\\ICT01_22\\Anaconda3\\envs\\tf_test\\lib\\site-packages\\tensorflow\\python\\ops\\rnn_cell_impl.py:459: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:Entity <bound method BasicRNNCell.call of <tensorflow.python.ops.rnn_cell_impl.BasicRNNCell object at 0x0000024BF0BDB1C8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BasicRNNCell.call of <tensorflow.python.ops.rnn_cell_impl.BasicRNNCell object at 0x0000024BF0BDB1C8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method BasicRNNCell.call of <tensorflow.python.ops.rnn_cell_impl.BasicRNNCell object at 0x0000024BF0BDB1C8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BasicRNNCell.call of <tensorflow.python.ops.rnn_cell_impl.BasicRNNCell object at 0x0000024BF0BDB1C8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method BasicRNNCell.call of <tensorflow.python.ops.rnn_cell_impl.BasicRNNCell object at 0x0000024BF0E09108>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BasicRNNCell.call of <tensorflow.python.ops.rnn_cell_impl.BasicRNNCell object at 0x0000024BF0E09108>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method BasicRNNCell.call of <tensorflow.python.ops.rnn_cell_impl.BasicRNNCell object at 0x0000024BF0E09108>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BasicRNNCell.call of <tensorflow.python.ops.rnn_cell_impl.BasicRNNCell object at 0x0000024BF0E09108>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method BasicRNNCell.call of <tensorflow.python.ops.rnn_cell_impl.BasicRNNCell object at 0x0000024BF1B3C788>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BasicRNNCell.call of <tensorflow.python.ops.rnn_cell_impl.BasicRNNCell object at 0x0000024BF1B3C788>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method BasicRNNCell.call of <tensorflow.python.ops.rnn_cell_impl.BasicRNNCell object at 0x0000024BF1B3C788>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BasicRNNCell.call of <tensorflow.python.ops.rnn_cell_impl.BasicRNNCell object at 0x0000024BF1B3C788>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:From <ipython-input-6-f15a440fa410>:9: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.dense instead.\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x0000024B80228948>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x0000024B80228948>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x0000024B80228948>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x0000024B80228948>>: AssertionError: Bad argument number for Name: 3, expecting 4\n"
     ]
    }
   ],
   "source": [
    "# dynamic_rnn : 셀로 입력 되는 데이터의 개수 맞춰서 셀을 구성\n",
    "# 나는 학교에 간다. static_rnn 동일한 사이즈 : 큰것 기준.\n",
    "# 입력사이즈 변동 = 가중치 조절 -> 나가는 특징은 똑같음\n",
    "# 3층 셀이 28개가 조성 : 고정사이즈\n",
    "outputs, states = tf.nn.dynamic_rnn(multi_layer_cell, X, dtype=tf.float32)\n",
    "# state가 몇개가 발생하는가?\n",
    "# 3 * 150 * 100\n",
    "states_concat = tf.concat(axis=1, values=states) # 150 *300\n",
    "logits = tf.layers.dense(states_concat, n_outputs) # 가중치 : 300 * 10\n",
    "# logits 150*10 / 150은 미니배치 사이즈 / 10개는 확률 특징\n",
    "xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y,\n",
    "                                                         logits=logits)\n",
    "loss = tf.reduce_mean(xentropy)\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)\n",
    "training_op = optimizer.minimize(loss)\n",
    "correct = tf.nn.in_top_k(logits,y,1)\n",
    "accuracy = tf.reduce_mean(tf.cast(correct,tf.float32))\n",
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 train accuracy: 0.91333336 test acuuracy : 0.9332\n",
      "1 train accuracy: 0.97333336 test acuuracy : 0.9584\n",
      "2 train accuracy: 0.98 test acuuracy : 0.9709\n",
      "3 train accuracy: 0.98 test acuuracy : 0.9692\n",
      "4 train accuracy: 0.98 test acuuracy : 0.9761\n",
      "5 train accuracy: 0.99333334 test acuuracy : 0.9738\n",
      "6 train accuracy: 1.0 test acuuracy : 0.9753\n",
      "7 train accuracy: 0.9866667 test acuuracy : 0.9766\n",
      "8 train accuracy: 0.98 test acuuracy : 0.9806\n",
      "9 train accuracy: 0.99333334 test acuuracy : 0.9806\n",
      "10 train accuracy: 0.99333334 test acuuracy : 0.9787\n",
      "11 train accuracy: 0.98 test acuuracy : 0.9794\n",
      "12 train accuracy: 0.9866667 test acuuracy : 0.9769\n",
      "13 train accuracy: 1.0 test acuuracy : 0.983\n",
      "14 train accuracy: 0.99333334 test acuuracy : 0.98\n",
      "15 train accuracy: 0.98 test acuuracy : 0.9804\n",
      "16 train accuracy: 1.0 test acuuracy : 0.9839\n",
      "17 train accuracy: 0.98 test acuuracy : 0.9839\n",
      "18 train accuracy: 0.9866667 test acuuracy : 0.9809\n",
      "19 train accuracy: 0.99333334 test acuuracy : 0.9827\n",
      "20 train accuracy: 0.9866667 test acuuracy : 0.986\n",
      "21 train accuracy: 0.9866667 test acuuracy : 0.9835\n",
      "22 train accuracy: 0.9866667 test acuuracy : 0.9855\n",
      "23 train accuracy: 0.99333334 test acuuracy : 0.9864\n",
      "24 train accuracy: 0.98 test acuuracy : 0.9832\n",
      "25 train accuracy: 0.9866667 test acuuracy : 0.9812\n",
      "26 train accuracy: 0.9866667 test acuuracy : 0.9854\n",
      "27 train accuracy: 1.0 test acuuracy : 0.9842\n",
      "28 train accuracy: 0.99333334 test acuuracy : 0.9837\n",
      "29 train accuracy: 0.99333334 test acuuracy : 0.9869\n",
      "30 train accuracy: 0.9866667 test acuuracy : 0.9846\n",
      "31 train accuracy: 1.0 test acuuracy : 0.9848\n",
      "32 train accuracy: 1.0 test acuuracy : 0.9818\n",
      "33 train accuracy: 1.0 test acuuracy : 0.9861\n",
      "34 train accuracy: 1.0 test acuuracy : 0.982\n",
      "35 train accuracy: 1.0 test acuuracy : 0.9831\n",
      "36 train accuracy: 1.0 test acuuracy : 0.9774\n",
      "37 train accuracy: 0.99333334 test acuuracy : 0.9845\n",
      "38 train accuracy: 0.9866667 test acuuracy : 0.982\n",
      "39 train accuracy: 0.9866667 test acuuracy : 0.984\n",
      "40 train accuracy: 0.99333334 test acuuracy : 0.9863\n",
      "41 train accuracy: 0.99333334 test acuuracy : 0.9852\n",
      "42 train accuracy: 0.9866667 test acuuracy : 0.9833\n",
      "43 train accuracy: 0.99333334 test acuuracy : 0.9835\n",
      "44 train accuracy: 0.99333334 test acuuracy : 0.9858\n",
      "45 train accuracy: 0.99333334 test acuuracy : 0.9864\n",
      "46 train accuracy: 0.99333334 test acuuracy : 0.9822\n",
      "47 train accuracy: 1.0 test acuuracy : 0.9883\n",
      "48 train accuracy: 0.99333334 test acuuracy : 0.9847\n",
      "49 train accuracy: 1.0 test acuuracy : 0.985\n",
      "50 train accuracy: 0.99333334 test acuuracy : 0.9843\n",
      "51 train accuracy: 1.0 test acuuracy : 0.9833\n",
      "52 train accuracy: 1.0 test acuuracy : 0.9871\n",
      "53 train accuracy: 1.0 test acuuracy : 0.9845\n",
      "54 train accuracy: 1.0 test acuuracy : 0.986\n",
      "55 train accuracy: 0.99333334 test acuuracy : 0.9857\n",
      "56 train accuracy: 1.0 test acuuracy : 0.9866\n",
      "57 train accuracy: 0.99333334 test acuuracy : 0.9856\n",
      "58 train accuracy: 0.99333334 test acuuracy : 0.986\n",
      "59 train accuracy: 1.0 test acuuracy : 0.9856\n",
      "60 train accuracy: 1.0 test acuuracy : 0.9863\n",
      "61 train accuracy: 1.0 test acuuracy : 0.9811\n",
      "62 train accuracy: 1.0 test acuuracy : 0.986\n",
      "63 train accuracy: 0.99333334 test acuuracy : 0.9854\n",
      "64 train accuracy: 1.0 test acuuracy : 0.9887\n",
      "65 train accuracy: 0.99333334 test acuuracy : 0.9842\n",
      "66 train accuracy: 1.0 test acuuracy : 0.9839\n",
      "67 train accuracy: 1.0 test acuuracy : 0.9836\n",
      "68 train accuracy: 1.0 test acuuracy : 0.985\n",
      "69 train accuracy: 1.0 test acuuracy : 0.9839\n",
      "70 train accuracy: 1.0 test acuuracy : 0.9819\n",
      "71 train accuracy: 1.0 test acuuracy : 0.9837\n",
      "72 train accuracy: 1.0 test acuuracy : 0.9859\n",
      "73 train accuracy: 1.0 test acuuracy : 0.9859\n",
      "74 train accuracy: 1.0 test acuuracy : 0.9848\n",
      "75 train accuracy: 1.0 test acuuracy : 0.989\n",
      "76 train accuracy: 1.0 test acuuracy : 0.9833\n",
      "77 train accuracy: 1.0 test acuuracy : 0.9875\n",
      "78 train accuracy: 1.0 test acuuracy : 0.9866\n",
      "79 train accuracy: 1.0 test acuuracy : 0.988\n",
      "80 train accuracy: 0.99333334 test acuuracy : 0.9843\n",
      "81 train accuracy: 1.0 test acuuracy : 0.9877\n",
      "82 train accuracy: 1.0 test acuuracy : 0.9761\n",
      "83 train accuracy: 1.0 test acuuracy : 0.9878\n",
      "84 train accuracy: 0.99333334 test acuuracy : 0.9844\n",
      "85 train accuracy: 0.99333334 test acuuracy : 0.9858\n",
      "86 train accuracy: 1.0 test acuuracy : 0.987\n",
      "87 train accuracy: 0.99333334 test acuuracy : 0.983\n",
      "88 train accuracy: 1.0 test acuuracy : 0.985\n",
      "89 train accuracy: 1.0 test acuuracy : 0.9848\n",
      "90 train accuracy: 1.0 test acuuracy : 0.9865\n",
      "91 train accuracy: 1.0 test acuuracy : 0.9857\n",
      "92 train accuracy: 0.99333334 test acuuracy : 0.9842\n",
      "93 train accuracy: 1.0 test acuuracy : 0.9858\n",
      "94 train accuracy: 1.0 test acuuracy : 0.9864\n",
      "95 train accuracy: 1.0 test acuuracy : 0.9867\n",
      "96 train accuracy: 1.0 test acuuracy : 0.9859\n",
      "97 train accuracy: 1.0 test acuuracy : 0.9878\n",
      "98 train accuracy: 0.99333334 test acuuracy : 0.9865\n",
      "99 train accuracy: 1.0 test acuuracy : 0.9849\n",
      "끝 입니다.\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 100\n",
    "batch_size = 150\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    for epoch in range(n_epochs):\n",
    "        for iteration in range(mnist.train.num_examples // batch_size): # 20000*150 돌고 그담에 epoch 만큼 더돌림\n",
    "            X_batch, y_batch = mnist.train.next_batch(batch_size)\n",
    "            # 이미지 사이즈로 생성\n",
    "            X_batch = X_batch.reshape((-1, n_steps, n_inputs))\n",
    "            sess.run(training_op, feed_dict={X: X_batch,\n",
    "                                            y:y_batch})\n",
    "        acc_train = accuracy.eval(feed_dict={X:X_batch,\n",
    "                                            y:y_batch})\n",
    "        acc_test = accuracy.eval(feed_dict={X:X_test,\n",
    "                                           y:y_test})\n",
    "        print(epoch, \"train accuracy:\", acc_train,\n",
    "             \"test acuuracy :\", acc_test)\n",
    "    print(\"끝 입니다.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\ICT01_22\\Anaconda3\\envs\\tf_test\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\base.py:252: _internal_retry.<locals>.wrap.<locals>.wrapped_fn (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use urllib or similar directly.\n",
      "Successfully downloaded train-images-idx3-ubyte.gz 9912422 bytes.\n",
      "Extracting ./mnist/data/train-images-idx3-ubyte.gz\n",
      "Successfully downloaded train-labels-idx1-ubyte.gz 28881 bytes.\n",
      "Extracting ./mnist/data/train-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From C:\\Users\\ICT01_22\\Anaconda3\\envs\\tf_test\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.one_hot on tensors.\n",
      "Successfully downloaded t10k-images-idx3-ubyte.gz 1648877 bytes.\n",
      "Extracting ./mnist/data/t10k-images-idx3-ubyte.gz\n",
      "Successfully downloaded t10k-labels-idx1-ubyte.gz 4542 bytes.\n",
      "Extracting ./mnist/data/t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:Entity <bound method BasicRNNCell.call of <tensorflow.python.ops.rnn_cell_impl.BasicRNNCell object at 0x0000024B809A49C8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BasicRNNCell.call of <tensorflow.python.ops.rnn_cell_impl.BasicRNNCell object at 0x0000024B809A49C8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method BasicRNNCell.call of <tensorflow.python.ops.rnn_cell_impl.BasicRNNCell object at 0x0000024B809A49C8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BasicRNNCell.call of <tensorflow.python.ops.rnn_cell_impl.BasicRNNCell object at 0x0000024B809A49C8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:From <ipython-input-8-3aea19c6941a>:24: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n",
      "\n",
      "Epoch:  0001 Avg cost = 0.503\n",
      "Epoch:  0002 Avg cost = 0.231\n",
      "Epoch:  0003 Avg cost = 0.174\n",
      "Epoch:  0004 Avg cost = 0.146\n",
      "Epoch:  0005 Avg cost = 0.135\n",
      "Epoch:  0006 Avg cost = 0.123\n",
      "Epoch:  0007 Avg cost = 0.122\n",
      "Epoch:  0008 Avg cost = 0.112\n",
      "Epoch:  0009 Avg cost = 0.107\n",
      "Epoch:  0010 Avg cost = 0.096\n",
      "최적화 완료!\n"
     ]
    }
   ],
   "source": [
    "#http://blog.naver.com/PostView.nhn?blogId=magnking&logNo=221323257045&redirect=Dlog&widgetTypeCall=true&directAccess=false\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.framework import ops\n",
    "ops.reset_default_graph()\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"./mnist/data/\", one_hot=True)\n",
    "learning_rate = 0.001\n",
    "total_epoch = 10\n",
    "batch_size = 128 # 가중치를 갱신하는 단위 배치사이즈\n",
    "n_input = 28 # 가로 28개\n",
    "n_step = 28 # 세로 28개 \n",
    "n_hidden = 128 # 128개의 특성을 추출하겠다. 은닉층의 노드갯수\n",
    "n_class = 10 # 분류하고자 하는 카테고리수\n",
    "X = tf.placeholder(tf.float32, [None, n_step, n_input]) # 입력층/ ?*가로28*세로28\n",
    "Y = tf.placeholder(tf.float32, [None, n_class]) # 출력층 ? * 10(카테고리수)\n",
    "W = tf.Variable(tf.random_normal([n_hidden, n_class])) # 가중치 128*10\n",
    "# 형태가 은닉층의 노드수와 출력층의 노드수를 맞추는것\n",
    "b = tf.Variable(tf.random_normal([n_class])) # 10\n",
    "cell = tf.nn.rnn_cell.BasicRNNCell(n_hidden) # neurons : 128\n",
    "# tf.nn.rnn_cell.BasicRNNCell 이거는 셀만들어주는함수 n_hidden 수만큼 노드생성\n",
    "# 그 외 GRUCell 등이 있음\n",
    "outputs, states = tf.nn.dynamic_rnn(cell, X, dtype=tf.float32)\n",
    "# RNNCell에 의해서 정의된 Recurrent neural network를 생성 즉 \n",
    "# RNN신경망을 구축해줌\n",
    "# 여기서 outputs 과 states를 반환받음. 신경망 생성완료\n",
    "outputs = tf.transpose(outputs, [1,0,2])\n",
    "# 128*28*128 -> 28*128*128\n",
    "outputs = outputs[-1]# 28을 날림 128*128\n",
    "model = tf.matmul(outputs, W) + b # 128*128  + 128*10 -> 128*10\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=model, labels=Y))\n",
    "# 분류를 위한 RNN이기 때문에 softmax를 사용\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate).minimize(cost)\n",
    "\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "# 60000 / 128\n",
    "total_batch = int(mnist.train.num_examples/batch_size)\n",
    "for epoch in range(total_epoch): # 10\n",
    "    total_cost = 0\n",
    "    for i in range(total_batch):\n",
    "        batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n",
    "        batch_xs = batch_xs.reshape((batch_size, n_step, n_input))\n",
    "        _, cost_val = sess.run([optimizer, cost], feed_dict={X: batch_xs, Y: batch_ys})\n",
    "        # _언더바는 파이썬이 계산한 마지막 결과가 저장되는 것\n",
    "        total_cost += cost_val\n",
    "    print('Epoch: ', '%04d' % (epoch + 1),\n",
    "         'Avg cost =', '{:.3f}'.format(total_cost/total_batch))\n",
    "print('최적화 완료!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 문제\n",
    "1. 테스트 데이터를 이용하여 테스트 하는 회로를 구성하시오\n",
    "2. 3개의 셀을 갖는 multi layer cell로 수정하시오.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# BasicRNNCell\n",
    "# MultiRNNCell : 수직으로 레이어 구성\n",
    "# dynamic_rnn : 모델\n",
    "tf.reset_default_graph()\n",
    "n_steps = 28\n",
    "n_inputs = 28\n",
    "n_outputs = 10\n",
    "learning_rate = 0.001\n",
    "X = tf.placeholder(tf.float32, [None, n_steps, n_inputs])\n",
    "y = tf.placeholder(tf.int32, [None])\n",
    "n_neurons = 100\n",
    "n_layers = 3 #3개의 멀티레이어 (3개의 셀 생성, 3개를 조합해서 MultiRNNCell 만들기)\n",
    "layers = [tf.contrib.rnn.BasicRNNCell(num_units=n_neurons, activation=tf.nn.relu) for layer in range(n_layers)]\n",
    "# 3개의 셀로 멀티레이어를 생성해도 output은 하나의 셀일 경우와 동일함\n",
    "# state에서는 3개의 레이어마다 \n",
    "multi_layer_cell = tf.contrib.rnn.MultiRNNCell(layers)\n",
    "# dynamic rnn : 셀로 입력되는 데이터의 개수에 맞춰 셀을 구성\n",
    "# 입력 사이즈 변동 = 가중치 조절 => 나가는 특징은 일차 (neural 수가 같음)\n",
    "# static rnn 동일한 사이즈 (큰 것 기준, 작은 것은 padding)\n",
    "# 3층 셀이 28개 조성 : 고정 사이즈\n",
    "outputs, states = tf.nn.dynamic_rnn(multi_layer_cell, X, dtype=tf.float32)\n",
    "outputs = tf.transpose(outputs, [1,0,2])\n",
    "#\n",
    "states_concat = tf.concat(axis=1, values=states) \n",
    "logits = tf.layers.dense(states_concat, n_outputs) \n",
    "xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y, logits=logits)\n",
    "loss = tf.reduce_mean(xentropy)\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)\n",
    "training_op = optimizer.minimize(loss)\n",
    "correct = tf.nn.in_top_k(logits, y, 1)\n",
    "accuracy = tf.reduce_mean(tf.cast(correct, tf.float32))\n",
    "init = tf.global_variables_initializer()\n",
    "#\n",
    "n_epochs = 100\n",
    "batch_size = 150\n",
    "\n",
    "sess = tf.Session() \n",
    "init.run()\n",
    "for epoch in range(n_epochs):\n",
    "    for iteration in range(mnist.train.num_examples // batch_size): # 20000*150 돌고 그담에 epoch 만큼 더돌림\n",
    "        X_batch, y_batch = mnist.train.next_batch(batch_size)\n",
    "        # 이미지 사이즈로 생성\n",
    "        X_batch = X_batch.reshape((-1, n_steps, n_inputs))\n",
    "        sess.run(training_op, feed_dict={X: X_batch,\n",
    "                                        y:y_batch})\n",
    "    acc_train = accuracy.eval(feed_dict={X:X_batch,\n",
    "                                        y:y_batch})\n",
    "    acc_test = accuracy.eval(feed_dict={X:X_test,\n",
    "                                       y:y_test})\n",
    "    print(epoch, \"train accuracy:\", acc_train,\n",
    "         \"test acuuracy :\", acc_test)\n",
    "print(\"끝 입니다.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "is_correct = tf.equal(tf.argmax(model,1),tf.argmax(Y,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(is.correct, tf.float32))\n",
    "test_batch_size=len(mnist.test.image)\n",
    "test_xs = mnist.test.image.reshape(test_batch_size,n_step,n_input)\n",
    "test_ys = mnist.test.labels\n",
    "print(\"정확도 : \", sess.run(accuracy, feed_dict={X:test_xs,Y:test_ys}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"rnn/transpose_1:0\", shape=(2, 3, 100), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "values2311 = np.array([\n",
    "    [[1],[2],[3]],\n",
    "    [[2],[3],[4]]\n",
    "])\n",
    "print(outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape (2, 3, 1)\n",
      "WARNING:tensorflow:Entity <bound method LSTMCell.call of <tensorflow.python.ops.rnn_cell_impl.LSTMCell object at 0x0000024B84946948>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LSTMCell.call of <tensorflow.python.ops.rnn_cell_impl.LSTMCell object at 0x0000024B84946948>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <bound method LSTMCell.call of <tensorflow.python.ops.rnn_cell_impl.LSTMCell object at 0x0000024B84946948>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LSTMCell.call of <tensorflow.python.ops.rnn_cell_impl.LSTMCell object at 0x0000024B84946948>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "(2, 100)\n",
      "(2, 100)\n",
      "rnn이 출력하는 outputs의 의미 (2, 3, 100)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "values231 = np.\n",
    "\n",
    "array([\n",
    "    [[1],[2],[3]],\n",
    "    [[2],[3],[4]]\n",
    "])\n",
    "print(\"shape\", values231.shape)\n",
    "import tensorflow as tf\n",
    "tf.reset_default_graph()\n",
    "tf_values231 = tf.constant(values231, dtype = tf.float32)\n",
    "lstm_cell = tf.contrib.rnn.LSTMCell(num_units=100)\n",
    "# rnn 모델은 동일 : 망과 망을 연결할 때(번역망 : 한글, 영어)\n",
    "outputs, state = tf.nn.dynamic_rnn(cell=lstm_cell,\n",
    "                                  dtype=tf.float32,inputs=tf_values231)\n",
    "print(state.c.shape) # 2*100 control state\n",
    "print(state.h.shape) # 2*100 hidden state\n",
    "# 이 둘이 연결해줌\n",
    "# latent time 지연시간\n",
    "print(\"rnn이 출력하는 outputs의 의미\", outputs.shape)\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    output_run, state_run = sess.run([outputs, state])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-23-d13416d25a1f>:8: bidirectional_dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `keras.layers.Bidirectional(keras.layers.RNN(cell))`, which is equivalent to this API\n",
      "WARNING:tensorflow:Entity <bound method LSTMCell.call of <tensorflow.python.ops.rnn_cell_impl.LSTMCell object at 0x0000024B84A90548>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LSTMCell.call of <tensorflow.python.ops.rnn_cell_impl.LSTMCell object at 0x0000024B84A90548>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <bound method LSTMCell.call of <tensorflow.python.ops.rnn_cell_impl.LSTMCell object at 0x0000024B84A90548>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LSTMCell.call of <tensorflow.python.ops.rnn_cell_impl.LSTMCell object at 0x0000024B84A90548>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <bound method LSTMCell.call of <tensorflow.python.ops.rnn_cell_impl.LSTMCell object at 0x0000024B84A90048>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LSTMCell.call of <tensorflow.python.ops.rnn_cell_impl.LSTMCell object at 0x0000024B84A90048>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <bound method LSTMCell.call of <tensorflow.python.ops.rnn_cell_impl.LSTMCell object at 0x0000024B84A90048>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LSTMCell.call of <tensorflow.python.ops.rnn_cell_impl.LSTMCell object at 0x0000024B84A90048>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "(2, 3, 100)\n",
      "(2, 3, 100)\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "values = tf.constant(np.array([\n",
    "    [[1],[2],[3]],\n",
    "    [[2],[3],[4]]\n",
    "]), dtype = tf.float32)\n",
    "lstm_cell_fw = tf.contrib.rnn.LSTMCell(100)\n",
    "lstm_cell_bw = tf.contrib.rnn.LSTMCell(100)\n",
    "(output_fw, output_bw), (output_state_fw,output_state_bw) = tf.nn.bidirectional_dynamic_rnn(cell_fw=lstm_cell_fw,cell_bw=lstm_cell_bw,inputs=values,dtype=tf.float32)\n",
    "# 양방향 LSTM\n",
    "# Multi cell : 셀에서\n",
    "print(output_fw.shape)\n",
    "print(output_bw.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.contrib import rnn\n",
    "import pprint\n",
    "from tensorflow.python.framework import ops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 5, 4)\n",
      "array([[[1., 0., 0., 0.],\n",
      "        [0., 1., 0., 0.],\n",
      "        [0., 0., 1., 0.],\n",
      "        [0., 0., 1., 0.],\n",
      "        [0., 0., 0., 1.]]], dtype=float32)\n",
      "WARNING:tensorflow:Entity <bound method BasicRNNCell.call of <tensorflow.python.ops.rnn_cell_impl.BasicRNNCell object at 0x0000024C02DE8088>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BasicRNNCell.call of <tensorflow.python.ops.rnn_cell_impl.BasicRNNCell object at 0x0000024C02DE8088>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method BasicRNNCell.call of <tensorflow.python.ops.rnn_cell_impl.BasicRNNCell object at 0x0000024C02DE8088>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BasicRNNCell.call of <tensorflow.python.ops.rnn_cell_impl.BasicRNNCell object at 0x0000024C02DE8088>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "array([[[ 0.12575956, -0.38949594],\n",
      "        [ 0.5346042 , -0.49213177],\n",
      "        [ 0.070356  , -0.4614423 ],\n",
      "        [-0.03998384, -0.32661176],\n",
      "        [ 0.29785615, -0.4337406 ]]], dtype=float32)\n",
      "(1, 5, 2)\n",
      "(1, 2)\n",
      "array([[ 0.29785615, -0.4337406 ]], dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "ops.reset_default_graph()\n",
    "pp = pprint.PrettyPrinter(indent=4)\n",
    "sess = tf.InteractiveSession()\n",
    "h = [1,0,0,0]\n",
    "e = [0,1,0,0]\n",
    "l = [0,0,1,0]\n",
    "o = [0,0,0,1]\n",
    "with tf.variable_scope('five_sequences') as scope:\n",
    "    hidden_size = 2\n",
    "    cell = tf.contrib.rnn.BasicRNNCell(num_units=hidden_size)\n",
    "    x_data = np.array([[h,e,l,l,o]], dtype = np.float32)\n",
    "    print(x_data.shape)\n",
    "    pp.pprint(x_data)\n",
    "    outputs, states = tf.nn.dynamic_rnn(cell,x_data,dtype=tf.float32)\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    pp.pprint(outputs.eval())\n",
    "    print(outputs.shape)\n",
    "    print(states.shape)\n",
    "    pp.pprint(states.eval())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "char_arr = ['a','b','c','d','e','f','g','h','i','j','k','l','m','n','o','p',\n",
    "           'q','r','s','t','u','v','w','x','y','z']\n",
    "# 총 26개\n",
    "num_dic = {n: i for i, n in enumerate(char_arr)}\n",
    "#  0:a ~ 쭉입력\n",
    "dic_len = len(num_dic)\n",
    "seq_data = ['word', 'wood', 'deep', 'dive', 'cold', 'cool', 'load',\n",
    "           'love', 'kiss','kind']\n",
    "# 26 * 26 행렬\n",
    "# 10000000000000000000000000\n",
    "# 01000000000000000000000000\n",
    "# 00100000000000000000000000\n",
    "def make_batch(seq_data):  # 자동으로 문자를 원핫인코딩\n",
    "    input_batch = []\n",
    "    target_batch = []\n",
    "    for seq in seq_data: # 'word' 부터 순차적으로 가져옴\n",
    "        input = [num_dic[n] for n in seq[:-1]] # 처음부터 마지막까지 뽑아냄\n",
    "        # w = 22, o = 14, r = 17 까지만\n",
    "        target = num_dic[seq[-1]] # d = 3 \n",
    "        input_batch.append(np.eye(dic_len)[input]) # 원핫 인코딩\n",
    "        target_batch.append(target)\n",
    "    return input_batch, target_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "ops.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Entity <bound method MultiRNNCell.call of <tensorflow.python.ops.rnn_cell_impl.MultiRNNCell object at 0x0000024CFD2FDF88>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiRNNCell.call of <tensorflow.python.ops.rnn_cell_impl.MultiRNNCell object at 0x0000024CFD2FDF88>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <bound method MultiRNNCell.call of <tensorflow.python.ops.rnn_cell_impl.MultiRNNCell object at 0x0000024CFD2FDF88>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiRNNCell.call of <tensorflow.python.ops.rnn_cell_impl.MultiRNNCell object at 0x0000024CFD2FDF88>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <bound method BasicLSTMCell.call of <tensorflow.python.ops.rnn_cell_impl.BasicLSTMCell object at 0x0000024CFD3096C8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BasicLSTMCell.call of <tensorflow.python.ops.rnn_cell_impl.BasicLSTMCell object at 0x0000024CFD3096C8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method BasicLSTMCell.call of <tensorflow.python.ops.rnn_cell_impl.BasicLSTMCell object at 0x0000024CFD3096C8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BasicLSTMCell.call of <tensorflow.python.ops.rnn_cell_impl.BasicLSTMCell object at 0x0000024CFD3096C8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method BasicLSTMCell.call of <tensorflow.python.ops.rnn_cell_impl.BasicLSTMCell object at 0x0000024D0A59F688>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BasicLSTMCell.call of <tensorflow.python.ops.rnn_cell_impl.BasicLSTMCell object at 0x0000024D0A59F688>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method BasicLSTMCell.call of <tensorflow.python.ops.rnn_cell_impl.BasicLSTMCell object at 0x0000024D0A59F688>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BasicLSTMCell.call of <tensorflow.python.ops.rnn_cell_impl.BasicLSTMCell object at 0x0000024D0A59F688>>: AssertionError: Bad argument number for Name: 3, expecting 4\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.contrib import rnn\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.framework import ops\n",
    "\n",
    "\n",
    "learning_rate = 0.01\n",
    "n_hidden = 128\n",
    "total_epoch = 30\n",
    "n_step = 3\n",
    "n_input = n_class = dic_len\n",
    "X = tf.placeholder(tf.float32, [None, n_step, n_input])\n",
    "Y = tf.placeholder(tf.int32, [None])\n",
    "W = tf.Variable(tf.random_normal([n_hidden,n_class]))\n",
    "b = tf.Variable(tf.random_normal([n_class]))\n",
    "\n",
    "cell1 = tf.nn.rnn_cell.BasicLSTMCell(n_hidden) # 특성수 128개\n",
    "cell1 = tf.nn.rnn_cell.DropoutWrapper(cell1, output_keep_prob=0.5, seed=10)\n",
    "cell2 = tf.nn.rnn_cell.BasicLSTMCell(n_hidden)\n",
    "# 2레이어로 구성된 멀티셀\n",
    "multi_cell = tf.nn.rnn_cell.MultiRNNCell([cell1,cell2])\n",
    "outputs, states = tf.nn.dynamic_rnn(multi_cell,X,dtype=tf.float32)\n",
    "# 10 * 3 * 128\n",
    "# 10 * 128\n",
    "outputs = tf.transpose(outputs, [1,0,2]) # 3 * 10 * 128\n",
    "outputs = outputs[-1] # 10 * 128\n",
    "model = tf.matmul(outputs, W) +b # 비선형 회귀방식\n",
    "# 분류\n",
    "cost = tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(logits=model, labels=Y))\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate).minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch :  0001 cost 3.664788\n",
      "Epoch :  0002 cost 2.511354\n",
      "Epoch :  0003 cost 1.505001\n",
      "Epoch :  0004 cost 1.259211\n",
      "Epoch :  0005 cost 0.739402\n",
      "Epoch :  0006 cost 0.816148\n",
      "Epoch :  0007 cost 0.386889\n",
      "Epoch :  0008 cost 0.772344\n",
      "Epoch :  0009 cost 0.334676\n",
      "Epoch :  0010 cost 0.312699\n",
      "Epoch :  0011 cost 0.231489\n",
      "Epoch :  0012 cost 0.325433\n",
      "Epoch :  0013 cost 0.245129\n",
      "Epoch :  0014 cost 0.136524\n",
      "Epoch :  0015 cost 0.312305\n",
      "Epoch :  0016 cost 0.032453\n",
      "Epoch :  0017 cost 0.105486\n",
      "Epoch :  0018 cost 0.054967\n",
      "Epoch :  0019 cost 0.040229\n",
      "Epoch :  0020 cost 0.213527\n",
      "Epoch :  0021 cost 0.014580\n",
      "Epoch :  0022 cost 0.057972\n",
      "Epoch :  0023 cost 0.201457\n",
      "Epoch :  0024 cost 0.016443\n",
      "Epoch :  0025 cost 0.011322\n",
      "Epoch :  0026 cost 0.023502\n",
      "Epoch :  0027 cost 0.020718\n",
      "Epoch :  0028 cost 0.139725\n",
      "Epoch :  0029 cost 0.020285\n",
      "Epoch :  0030 cost 0.012062\n"
     ]
    }
   ],
   "source": [
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "input_batch, target_batch = make_batch(seq_data) # 단어데이터\n",
    "\n",
    "for epoch in range(total_epoch):\n",
    "    _, loss = sess.run([optimizer,cost],feed_dict={X: input_batch, Y:target_batch})\n",
    "    print(\"Epoch : \",\"%04d\"%(epoch+1),\"cost\",\"{:6f}\".format(loss) )\n",
    "print(acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 3  3 15  4  3 11  3  4 18  3]\n",
      "1.0\n",
      "입력값: ['wor ', 'woo ', 'dee ', 'div ', 'col ', 'coo ', 'loa ', 'lov ', 'kis ', 'kin ']\n",
      "예측값: ['word', 'wood', 'deep', 'dive', 'cold', 'cool', 'load', 'love', 'kiss', 'kind']\n",
      "정확도: 1.0\n"
     ]
    }
   ],
   "source": [
    "prediction = tf.cast(tf.argmax(model,1),tf.int32)\n",
    "prediction_check = tf.equal(prediction,Y)\n",
    "accuracy = tf.reduce_mean(tf.cast(prediction_check, tf.float32))\n",
    "\n",
    "input_batch, target_batch = make_batch(seq_data)\n",
    "predict, accuracy_val = sess.run([prediction, accuracy],\n",
    "                               feed_dict={X:input_batch, Y:target_batch})\n",
    "print(predict)\n",
    "print(accuracy_val)\n",
    "predict_words = []\n",
    "for idx, val in enumerate(seq_data):\n",
    "    last_char = char_arr[predict[idx]]\n",
    "    predict_words.append(val[:3] + last_char)\n",
    "print(\"입력값:\",[w[:3] + ' ' for w in seq_data])\n",
    "print(\"예측값:\", predict_words)\n",
    "print(\"정확도:\", accuracy_val)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
