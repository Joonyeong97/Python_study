{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ICT01_06\\Anaconda3\\envs\\tf_test22\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\ICT01_06\\Anaconda3\\envs\\tf_test22\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\ICT01_06\\Anaconda3\\envs\\tf_test22\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\ICT01_06\\Anaconda3\\envs\\tf_test22\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\ICT01_06\\Anaconda3\\envs\\tf_test22\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\ICT01_06\\Anaconda3\\envs\\tf_test22\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "C:\\Users\\ICT01_06\\Anaconda3\\envs\\tf_test22\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\ICT01_06\\Anaconda3\\envs\\tf_test22\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\ICT01_06\\Anaconda3\\envs\\tf_test22\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\ICT01_06\\Anaconda3\\envs\\tf_test22\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\ICT01_06\\Anaconda3\\envs\\tf_test22\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\ICT01_06\\Anaconda3\\envs\\tf_test22\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-1-58bb93bec2c6>:5: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From C:\\Users\\ICT01_06\\Anaconda3\\envs\\tf_test22\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "WARNING:tensorflow:From C:\\Users\\ICT01_06\\Anaconda3\\envs\\tf_test22\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting ./mnist/data\\train-images-idx3-ubyte.gz\n",
      "WARNING:tensorflow:From C:\\Users\\ICT01_06\\Anaconda3\\envs\\tf_test22\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting ./mnist/data\\train-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From C:\\Users\\ICT01_06\\Anaconda3\\envs\\tf_test22\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.one_hot on tensors.\n",
      "Extracting ./mnist/data\\t10k-images-idx3-ubyte.gz\n",
      "Extracting ./mnist/data\\t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From C:\\Users\\ICT01_06\\Anaconda3\\envs\\tf_test22\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"./mnist/data\", one_hot = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_epoch = 100\n",
    "batch_size = 100\n",
    "learning_rate = 0.0002\n",
    "n_hidden = 256\n",
    "n_input = 28*28\n",
    "n_noise = 128\n",
    "X = tf.placeholder(tf.float32, [None, n_input])\n",
    "Z = tf.placeholder(tf.float32, [None, n_noise])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "G_W1 = tf.Variable(tf.random_normal([n_noise, n_hidden],stddev=0.01))\n",
    "G_b1 = tf.Variable(tf.zeros([n_hidden]))\n",
    "G_W2 = tf.Variable(tf.random_normal([n_hidden, n_input],stddev=0.01))\n",
    "G_b2 = tf.Variable(tf.zeros([n_input]))\n",
    "D_W1 = tf.Variable(tf.random_normal([n_input, n_hidden],stddev = 0.01))\n",
    "D_b1 = tf.Variable(tf.zeros([n_hidden]))\n",
    "D_W2 = tf.Variable(tf.random_normal([n_hidden, 1], stddev=0.01))\n",
    "D_b2 = tf.Variable(tf.zeros([1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 생성기와 판별기\n",
    "# cost function : 확률적 함수\n",
    "# MSE , Enthropy 분류\n",
    "# KL-Divergence : GAN, VAE - 분포의 차를 확인하는 함수\n",
    "# 생성기 -> noise 가 input 데이터, cost function : KL- Divergence\n",
    "# \n",
    "def generator(noise_z):\n",
    "    hidden = tf.nn.relu(tf.matmul(noise_z, G_W1)+G_b1) # \n",
    "    output = tf.nn.sigmoid(tf.matmul(hidden, G_W2) + G_b2)\n",
    "    return output\n",
    "def discriminator(inputs):\n",
    "    hidden = tf.nn.relu(tf.matmul(inputs,D_W1) + D_b1)\n",
    "    output = tf.nn.sigmoid(tf.matmul(hidden,D_W2) + D_b2)\n",
    "    return output\n",
    "def get_noise(batch_size, n_noise):\n",
    "    return np.random.normal(size = (batch_size,n_noise))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = generator(Z) # 노이즈 -> 이미지 생성\n",
    "D_gene = discriminator(G) # 이미지를 판별 - 분포를 확인한다\n",
    "# log 확률값 -> 정보량\n",
    "# 확률이 높아지면 정보량이 작아지고\n",
    "# 확률이 낮아지면 정보량이 커짐 tfidf의 논리를 고려할것\n",
    "# 가장 적합한 분포 -> 높은 것이 유리\n",
    "D_real = discriminator(X)\n",
    "# 마이너스를 붙이면 최대화 하기하는것\n",
    "loss_D = tf.reduce_mean(tf.log(D_real) + tf.log(1-D_gene))\n",
    "loss_G = tf.reduce_mean(tf.log(D_gene)) # 최대우도 추정법 -적합한 분포\n",
    "D_var_list = [D_W1, D_b1, D_W2, D_b2]\n",
    "G_var_list = [G_W1, G_b1, G_W2, G_b2]\n",
    "# 마이너스를 붙이면 최대화 하기하는것\n",
    "train_D = tf.train.AdamOptimizer(learning_rate).minimize(-loss_D, var_list=D_var_list)\n",
    "# 역전파 변수를 지정\n",
    "train_G = tf.train.AdamOptimizer(learning_rate).minimize(-loss_G, var_list=G_var_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "total_batch = int(mnist.train.num_examples/batch_size)\n",
    "loss_val_D, loss_val_G = 0,0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0000  D loss: -0.07162 G loss :-3.417\n",
      "Epoch: 0001  D loss: -0.4231 G loss :-1.664\n",
      "Epoch: 0002  D loss: -0.2935 G loss :-2.175\n",
      "Epoch: 0003  D loss: -0.3198 G loss :-2.316\n",
      "Epoch: 0004  D loss: -0.3284 G loss :-2.668\n",
      "Epoch: 0005  D loss: -0.1633 G loss :-3.273\n",
      "Epoch: 0006  D loss: -0.2076 G loss :-3.44\n",
      "Epoch: 0007  D loss: -0.2015 G loss :-3.65\n",
      "Epoch: 0008  D loss: -0.1456 G loss :-3.5\n",
      "Epoch: 0009  D loss: -0.222 G loss :-2.922\n",
      "Epoch: 0010  D loss: -0.331 G loss :-2.903\n",
      "Epoch: 0011  D loss: -0.3212 G loss :-2.821\n",
      "Epoch: 0012  D loss: -0.3999 G loss :-2.476\n",
      "Epoch: 0013  D loss: -0.2694 G loss :-2.82\n",
      "Epoch: 0014  D loss: -0.3285 G loss :-2.477\n",
      "Epoch: 0015  D loss: -0.309 G loss :-2.354\n",
      "Epoch: 0016  D loss: -0.5354 G loss :-2.527\n",
      "Epoch: 0017  D loss: -0.3869 G loss :-2.659\n",
      "Epoch: 0018  D loss: -0.399 G loss :-2.607\n",
      "Epoch: 0019  D loss: -0.3516 G loss :-2.693\n",
      "Epoch: 0020  D loss: -0.3731 G loss :-2.715\n",
      "Epoch: 0021  D loss: -0.5221 G loss :-2.363\n",
      "Epoch: 0022  D loss: -0.4307 G loss :-2.416\n",
      "Epoch: 0023  D loss: -0.5523 G loss :-2.111\n",
      "Epoch: 0024  D loss: -0.5587 G loss :-2.372\n",
      "Epoch: 0025  D loss: -0.6184 G loss :-2.003\n",
      "Epoch: 0026  D loss: -0.6705 G loss :-2.271\n",
      "Epoch: 0027  D loss: -0.732 G loss :-1.79\n",
      "Epoch: 0028  D loss: -0.7178 G loss :-2.017\n",
      "Epoch: 0029  D loss: -0.625 G loss :-2.503\n",
      "Epoch: 0030  D loss: -0.7248 G loss :-2.072\n",
      "Epoch: 0031  D loss: -0.7255 G loss :-2.067\n",
      "Epoch: 0032  D loss: -0.7188 G loss :-1.906\n",
      "Epoch: 0033  D loss: -0.8213 G loss :-1.861\n",
      "Epoch: 0034  D loss: -0.5874 G loss :-1.958\n",
      "Epoch: 0035  D loss: -0.7465 G loss :-1.972\n",
      "Epoch: 0036  D loss: -0.6492 G loss :-1.847\n",
      "Epoch: 0037  D loss: -0.6901 G loss :-1.988\n",
      "Epoch: 0038  D loss: -0.7682 G loss :-1.686\n",
      "Epoch: 0039  D loss: -0.9199 G loss :-1.73\n",
      "Epoch: 0040  D loss: -0.914 G loss :-1.867\n",
      "Epoch: 0041  D loss: -0.9211 G loss :-1.676\n",
      "Epoch: 0042  D loss: -0.7915 G loss :-1.562\n",
      "Epoch: 0043  D loss: -0.734 G loss :-1.901\n",
      "Epoch: 0044  D loss: -0.8484 G loss :-1.48\n",
      "Epoch: 0045  D loss: -0.8294 G loss :-1.718\n",
      "Epoch: 0046  D loss: -0.9475 G loss :-1.455\n",
      "Epoch: 0047  D loss: -1.006 G loss :-1.696\n",
      "Epoch: 0048  D loss: -0.9876 G loss :-1.475\n",
      "Epoch: 0049  D loss: -1.04 G loss :-1.428\n",
      "Epoch: 0050  D loss: -0.7984 G loss :-1.58\n",
      "Epoch: 0051  D loss: -0.9364 G loss :-1.674\n",
      "Epoch: 0052  D loss: -0.9373 G loss :-1.633\n",
      "Epoch: 0053  D loss: -0.799 G loss :-1.609\n",
      "Epoch: 0054  D loss: -0.8652 G loss :-1.437\n",
      "Epoch: 0055  D loss: -0.9963 G loss :-1.436\n",
      "Epoch: 0056  D loss: -0.8559 G loss :-1.551\n",
      "Epoch: 0057  D loss: -0.8468 G loss :-1.402\n",
      "Epoch: 0058  D loss: -1.082 G loss :-1.597\n",
      "Epoch: 0059  D loss: -0.8598 G loss :-1.56\n",
      "Epoch: 0060  D loss: -0.8138 G loss :-1.779\n",
      "Epoch: 0061  D loss: -0.9397 G loss :-1.478\n",
      "Epoch: 0062  D loss: -0.918 G loss :-1.554\n",
      "Epoch: 0063  D loss: -0.8635 G loss :-1.752\n",
      "Epoch: 0064  D loss: -1.02 G loss :-1.686\n",
      "Epoch: 0065  D loss: -0.8792 G loss :-1.815\n",
      "Epoch: 0066  D loss: -0.8872 G loss :-1.486\n",
      "Epoch: 0067  D loss: -0.8469 G loss :-1.703\n",
      "Epoch: 0068  D loss: -1.057 G loss :-1.505\n",
      "Epoch: 0069  D loss: -1.012 G loss :-1.367\n",
      "Epoch: 0070  D loss: -0.8955 G loss :-1.571\n",
      "Epoch: 0071  D loss: -0.8192 G loss :-1.518\n",
      "Epoch: 0072  D loss: -0.8662 G loss :-1.708\n",
      "Epoch: 0073  D loss: -0.8006 G loss :-1.572\n",
      "Epoch: 0074  D loss: -0.8877 G loss :-1.523\n",
      "Epoch: 0075  D loss: -0.9063 G loss :-1.558\n",
      "Epoch: 0076  D loss: -0.8807 G loss :-1.598\n",
      "Epoch: 0077  D loss: -0.9296 G loss :-1.723\n",
      "Epoch: 0078  D loss: -0.7805 G loss :-1.65\n",
      "Epoch: 0079  D loss: -0.9421 G loss :-1.654\n",
      "Epoch: 0080  D loss: -0.7681 G loss :-1.656\n",
      "Epoch: 0081  D loss: -0.9715 G loss :-1.7\n",
      "Epoch: 0082  D loss: -0.8965 G loss :-1.538\n",
      "Epoch: 0083  D loss: -0.9046 G loss :-1.608\n",
      "Epoch: 0084  D loss: -0.8413 G loss :-1.711\n",
      "Epoch: 0085  D loss: -0.8711 G loss :-1.849\n",
      "Epoch: 0086  D loss: -0.8515 G loss :-1.635\n",
      "Epoch: 0087  D loss: -0.8689 G loss :-1.678\n",
      "Epoch: 0088  D loss: -0.8515 G loss :-1.485\n",
      "Epoch: 0089  D loss: -0.7363 G loss :-1.776\n",
      "Epoch: 0090  D loss: -0.7774 G loss :-1.795\n",
      "Epoch: 0091  D loss: -0.8009 G loss :-1.662\n",
      "Epoch: 0092  D loss: -0.7574 G loss :-1.639\n",
      "Epoch: 0093  D loss: -0.7732 G loss :-1.709\n",
      "Epoch: 0094  D loss: -0.9248 G loss :-1.727\n",
      "Epoch: 0095  D loss: -0.9787 G loss :-1.644\n",
      "Epoch: 0096  D loss: -0.7423 G loss :-1.703\n",
      "Epoch: 0097  D loss: -0.7143 G loss :-2.008\n",
      "Epoch: 0098  D loss: -0.8652 G loss :-1.798\n",
      "Epoch: 0099  D loss: -0.7796 G loss :-1.722\n",
      "최적화완료\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for epoch in range(total_epoch):\n",
    "    for i in range(total_batch):\n",
    "        batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n",
    "        noise = get_noise(batch_size, n_noise)\n",
    "        _, loss_val_D = sess.run([train_D, loss_D],\n",
    "                                feed_dict={X:batch_xs, Z:noise})\n",
    "        _, loss_val_G = sess.run([train_G, loss_G], feed_dict={Z: noise})\n",
    "    print('Epoch:', '%04d' % epoch, ' D loss: {:.4}'.format(loss_val_D),\n",
    "          'G loss :{:.4}'.format(loss_val_G))\n",
    "    if epoch ==0 or (epoch +1) % 10 == 0:\n",
    "        sample_size =10\n",
    "        noise = get_noise(sample_size, n_noise)\n",
    "        samples = sess.run(G, feed_dict={Z: noise})\n",
    "        fig, ax = plt.subplots(1, sample_size, figsize=(sample_size, 1))\n",
    "        for i in range(sample_size):\n",
    "            ax[i].set_axis_off()\n",
    "            ax[i].imshow(np.reshape(samples[i], (28,28)))\n",
    "            plt.savefig('samples/{}.png'.format(str(epoch).zfill(3)), bbox_inches='tight')\n",
    "            plt.close(fig)\n",
    "print('최적화완료')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Precision not allowed in integer format specifier",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-71ef5f98d24d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m         \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss_val_D\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtrain_D\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss_D\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mbatch_xs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mZ\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mnoise\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m         \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss_val_D\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtrain_G\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss_G\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mZ\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mnoise\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Epoch %04d'\u001b[0m\u001b[1;33m%\u001b[0m\u001b[0mepoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'D loss: {:.4}'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss_val_D\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'G loss: {:.4}'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss_val_G\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mepoch\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;36m10\u001b[0m \u001b[1;33m==\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m         \u001b[0msample_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m10\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Precision not allowed in integer format specifier"
     ]
    }
   ],
   "source": [
    "for epoch in range(total_epoch):\n",
    "    for i in range(total_batch):\n",
    "        batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n",
    "        noise = get_noise(batch_size, n_noise)\n",
    "        _, loss_val_D = sess.run([train_D, loss_D], feed_dict={X:batch_xs,Z:noise})\n",
    "        # 이미지를 생성해줌 128 * 128 로 입력\n",
    "        _, loss_val_D = sess.run([train_G, loss_G], feed_dict={Z:noise})\n",
    "    print('Epoch %04d'%epoch,'D loss: {:.4}'.format(loss_val_D), 'G loss: {:.4}'.format(loss_val_G))\n",
    "    if epoch == 0 or (epoch+1) % 10 ==0:\n",
    "        sample_size = 10\n",
    "        noise = get_noise(sample_size, n_noise) # 10 * 128\n",
    "        samples = ses.run(G, feed_dict={Z: noise})\n",
    "        fig, ax = plt.subplot(1, sample_size, figsize=(sample_size,1))\n",
    "        for i in range(sample_size):\n",
    "            ax[i].set_axis_off()# 128 -> 784 이미지 사이즈\n",
    "            ax[i].imshow(np.reshape(samples[i], (28,28)))\n",
    "            plt.savefig('samples/{}.png'.format(str(epoch).zfill(3)),bbox_inches='tight')\n",
    "            plt.close(fig)\n",
    "print('최적화 완료')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
