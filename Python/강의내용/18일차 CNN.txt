CNN ( Convolution Neural Network )

모든 이미지는 사각형임~
한픽셀에 주변의 값들을 곱하고 더해주면 적분
필터의 사이즈가 작으면 작은특징 크면 큰특징을 찾아냄~

여러개의 특징을 뽑아내기위해서
필터를 여러개 사용해서 채널이 증가

random으로 초기화 시켜서 학습을 시킨다

신경망에서는 FFNN이 기본망
CNN은
앞단에서 특징을 추출하는것

특징을 뽑아낸놈들을 flatten 시켜서 일렬로 정렬

padding -> 기존에 100*100에서 필터링해서 98*98이되면 다시 100*100으로 하기위해서 한다 패딩

pooling -> 한픽셀의 특징이 주변 픽셀의 중복으로 추출되기때문에 삭제해도 무방 ex) 100*100 -> 50*50 으로 줄어듦

이미지는 3차원입니다.
가로 세로 RGB

CNN은 컨볼루션층으로 나눠져있음
기본신경망은 은닉층이있지만
CNN은 비슷한 컨볼루션층과 완전연결층이 나눠져있음 

conv = convolution
conv -> relu -> pooling
식으로 진행

convolution 이란? 
입력데이터와 가중치들의 집합체인 다양한 필터와의
컨볼루션 연산을 통해서 입력데이터의 특징을 추출하는 역할

pooling 이란?
입력정보를 최대값 or 최소값 or 평균값등으로 압축하여 데이터
연산량을 줄여주는 역할 수행
일반적으로 max값으로 출력을 진행함

padding 이란?
패딩이란 컨볼루션 연산을 수행하기 전에 입력데이터 주변을 특정 값
으로 채우는것을 말하며, 컨볼루션 연산에서 자주 이용되는방법
- 컨볼루션 연산을 수행하면 데이터 크기가(shape) 줄어드는 단점을
방지하기 위함


Conv 층
A1 입력받으면 필터후 + 바이어스 = 특징맵
그후 relu층 으로 연결 0보다 작으면 0으로 위면 그대로
그다음 pooling 층으로 maxpooling 실행 이 중간사이에 패딩을 넣어서
값의 손실을 막는것

즉 입력데이터 * 필터링 -> 컨볼루션 연산결과 + 바이어스 -> 특징맵 -> Relu-> pooling
-> 완전연결층( FLATTEN( 평평하게 ) ) -> 출력층

필터후 사이즈

입력데이터 크기(H , W) , 필터크기 (FH, FW), 패딩 P, 스트라이드 S일때
출력 데이터 크기  ( OH, OW )

OH = 	H + 2P -FH
	--------------    +   1
	       S

OW = 	W + 2P -FW
	--------------    +   1
	       S

예) 입력 ( 28 * 31 ), 필터(5 * 5), 패딩 2 , 스트라이드 3 -> 출력 (10,11)
OH = 	28 + 2*2 -5
	--------------    +   1    = 10
	       3

OW = 	31 + 2*2 -5
	--------------    +   1     = 11
	       3



입력데이터 * 필터링 -> 컨볼루션 연산결과 + 바이어스 -> 특징맵 -> Relu-> pooling
-> 완전연결층( FLATTEN( 평평하게 ) ) -> Linear regression -> softmax  -> 손실함수 최소값 확인


Softmax = 입력받은 값을 출력으로 0~1 사이의 값으로 모두 정규화하며
출력값들의 총합은 항상 1이 되도록 하는 역할 수행